{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Author: Linna An\n",
    "- Environment: `common_use`\n",
    "- Some prediction xml adapted from protocol generated by Dmitri & Derrick & Bcov\n",
    "- Version: 22.06.21\n",
    "- For ligands docking to pseudocycles to select suitable docks\n",
    "- all enumerate loops are for generate cmds for test. (aka, use n < 1, generate 1 cmd for test)\n",
    "- optimize 22.06.07: \n",
    "    - change all AF2 to batch run. \n",
    "    - change pyrosetta to Biopython to get sequence to save time. Get seq from pose use ~ 0.6sec, Biopython use 0.1 sec\n",
    "- optimize 22.06.21: \n",
    "    - Optimized predictor1, speed saved from 1.7sec to 1.28sec (jojo). \n",
    "    - Optimized predictor2, speed saved from 32.5sec to 4.3sec (jojo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import glob\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import subprocess\n",
    "from shutil import copyfile\n",
    "import tempfile\n",
    "import shutil\n",
    "from collections import defaultdict\n",
    "import xarray\n",
    "import gzip\n",
    "import time\n",
    "import json\n",
    "from Bio import SeqIO\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn import metrics\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "import scipy as sp\n",
    "import sklearn as sk\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import sklearn.metrics as sm\n",
    "%matplotlib inline\n",
    "pd.options.display.max_colwidth = 1000\n",
    "\n",
    "sys.path.append('./software/')\n",
    "from get_rmsds_functions import TMalign\n",
    "from get_rmsds_functions import get_RMSD\n",
    "import check_interactions_to_lig\n",
    "\n",
    "sys.path.append('./lib/')\n",
    "from libSlurm import make_submit_file\n",
    "from libSlurm import make_dist_plots\n",
    "from libSlurm import sed_inplace\n",
    "from libSlurm import grep\n",
    "from libSlurm import get_flags\n",
    "from libSlurm import plot_ROC\n",
    "from libCommonJupyterFunc import get_total_scores\n",
    "from check_interactions_to_lig import get_lig_num\n",
    "from check_interactions_to_lig import get_hb2lig\n",
    "import silent_tools # Bcov: https://github.com/bcov77/silent_tools.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_dir = '/home/linnaan/software/Pseudocycle_small_molecule_binder/' # change to where your scripts and ligands are, if you pull from git, then it should just be the git directory\n",
    "scratch_dir = '/net/scratch/linnaan/New_AF2_scaffolds/220214_dock/' # change to where you want to put your intermediate outputs\n",
    "\n",
    "#ligands\n",
    "# format: {name,[genot_param,ref2015_param, [rotamers],requirements,required_atms]}\n",
    "# required_atms should be adjusted based on rifgen rif size results. too small rif\n",
    "# hurt rifdock significantly\n",
    "ligands = {\n",
    "            'T44':['/home/linnaan/ligands/T44/sel_low_energy/good_to_use/T44_0001_relax_charged_genpot.params',\\\n",
    "                  '/home/linnaan/ligands/T44/sel_low_energy/good_to_use/T44_ref2015.params',\\\n",
    "                  [i for i in glob.glob('/home/linnaan/ligands/T44/sel_low_energy/good_to_use/T44_*_relax_charged_ref2015.pdb') if 'linker' not in i],\\\n",
    "                  '2,3,5,6,8,9','N1,H8,H9,H11,O3,O4,O1,O2,H10'],\n",
    "           } \n",
    "\n",
    "# Check burial of tail\n",
    "# edit manually\n",
    "# format: ligand_name: [check_burial_atom, linker_added_ligand_params,burial_cutoff (adjust this),\n",
    "#                     lig_heavy_atm,lig_aromatic_amds]\n",
    "ligands_tails = {\n",
    "                 'T44':['C16',\n",
    "                        '/home/linnaan/ligands/T44/sel_low_energy/T44_0005_relax_charged_ref2015_linker.params',\n",
    "                        7,(),\n",
    "                        ()],\n",
    "                } #add tail ligands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8719\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "      <th>Unnamed: 0.1.1.1</th>\n",
       "      <th>Unnamed: 0.1.1.1.1</th>\n",
       "      <th>Unnamed: 0.1.1.1.1.1</th>\n",
       "      <th>score</th>\n",
       "      <th>fa_atr</th>\n",
       "      <th>fa_rep</th>\n",
       "      <th>fa_sol</th>\n",
       "      <th>...</th>\n",
       "      <th>name_before_permute</th>\n",
       "      <th>dssp_bin_before_permute</th>\n",
       "      <th>cluster</th>\n",
       "      <th>pdb1</th>\n",
       "      <th>posfile_by_hull</th>\n",
       "      <th>nres</th>\n",
       "      <th>short_name</th>\n",
       "      <th>indi_cluster_dir</th>\n",
       "      <th>polar_bias_pssm_f</th>\n",
       "      <th>no_bias_pssm_f</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-305.763</td>\n",
       "      <td>-948.172</td>\n",
       "      <td>155.222</td>\n",
       "      <td>715.014</td>\n",
       "      <td>...</td>\n",
       "      <td>L_50_R_3_M_4_MR_5_MM_uniform_T_0_02_LW_4_0_2_0_1_0_20211031_192628_612107_AAA+_step_00469_dldesign_5_relax_0001_rank_1_relax.pdb</td>\n",
       "      <td>3/LHLHLHLHLHLHL_3/files.list</td>\n",
       "      <td>3/HHHHHH_3/62.list</td>\n",
       "      <td>L_50_R_3_M_4_MR_5_MM_uniform_T_0_02_LW_4_0_2_0_1_0_20211031_192628_612107_AAA+_step_00469_dldesign_5_relax_0001_rank_1_relax.pdb</td>\n",
       "      <td>/home/drhicks1/af2_cyclic_repeat_proteins/20220119_pocket_hull/L_50_R_3_M_4_MR_5_MM_uniform_T_0_02_LW_4_0_2_0_1_0_20211031_192628_612107_AAA+_step_00469_dldesign_5_relax_0001_rank_1_relax.pos</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3-HHHHHH_3-62</td>\n",
       "      <td>3/HHHHHH_3_62/</td>\n",
       "      <td>/home/linnaan/New_AF2_scaffolds/resampled_pseudocycles/PSSM/3/HHHHHH_3_62/L_50_R_3_M_4_MR_5_MM_uniform_T_0_02_LW_4_0_2_0_1_0_20211031_192628_612107_AAA+_step_00469_dldesign_5_relax_0001_rank_1_relax_dldesign_pbias.pssm</td>\n",
       "      <td>/home/linnaan/New_AF2_scaffolds/resampled_pseudocycles/PSSM/3/HHHHHH_3_62/L_50_R_3_M_4_MR_5_MM_uniform_T_0_02_LW_4_0_2_0_1_0_20211031_192628_612107_AAA+_step_00469_dldesign_5_relax_0001_rank_1_relax_dldesign_nobias.pssm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-253.208</td>\n",
       "      <td>-880.858</td>\n",
       "      <td>121.295</td>\n",
       "      <td>707.958</td>\n",
       "      <td>...</td>\n",
       "      <td>L_36_R_4_M_4_MR_5_MM_uniform_T_0_02_LW_4_0_2_0_1_0_20211024_005219_391887_AAAA+_step_00492_dldesign_2_relax_0001_rank_1_relax.pdb</td>\n",
       "      <td>4/LHLHLHLHLHLHLHLHLHL_4/files.list</td>\n",
       "      <td>4/HHHHHHHH_4/21.list</td>\n",
       "      <td>L_36_R_4_M_4_MR_5_MM_uniform_T_0_02_LW_4_0_2_0_1_0_20211024_005219_391887_AAAA+_step_00492_dldesign_2_relax_0001_rank_1_relax_20220103_171107_923767_permute_rank_1_relax.pdb</td>\n",
       "      <td>/home/drhicks1/af2_cyclic_repeat_proteins/20220119_pocket_hull/L_36_R_4_M_4_MR_5_MM_uniform_T_0_02_LW_4_0_2_0_1_0_20211024_005219_391887_AAAA+_step_00492_dldesign_2_relax_0001_rank_1_relax_20220103_171107_923767_permute_rank_1_relax.pos</td>\n",
       "      <td>144.0</td>\n",
       "      <td>4-HHHHHHHH_4-21</td>\n",
       "      <td>4/HHHHHHHH_4_21/</td>\n",
       "      <td>/home/linnaan/New_AF2_scaffolds/resampled_pseudocycles/PSSM/4/HHHHHHHH_4_21/L_36_R_4_M_4_MR_5_MM_uniform_T_0_02_LW_4_0_2_0_1_0_20211024_005219_391887_AAAA+_step_00492_dldesign_2_relax_0001_rank_1_relax_20220103_171107_923767_permute_rank_1_relax_dldesign_pbias.pssm</td>\n",
       "      <td>/home/linnaan/New_AF2_scaffolds/resampled_pseudocycles/PSSM/4/HHHHHHHH_4_21/L_36_R_4_M_4_MR_5_MM_uniform_T_0_02_LW_4_0_2_0_1_0_20211024_005219_391887_AAAA+_step_00492_dldesign_2_relax_0001_rank_1_relax_20220103_171107_923767_permute_rank_1_relax_dldesign_nobias.pssm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>-245.363</td>\n",
       "      <td>-776.541</td>\n",
       "      <td>89.400</td>\n",
       "      <td>650.947</td>\n",
       "      <td>...</td>\n",
       "      <td>L_32_R_4_M_3_MR_5_MM_uniform_T_0_02_LW_4_0_2_0_1_0_20211023_233141_820550_AAAA+_step_00496_dldesign_1_relax_0001_rank_1_relax.pdb</td>\n",
       "      <td>4/LHLHLHLHLHLHLHLHL_4/files.list</td>\n",
       "      <td>4/HHHHHHHH_4/735.list</td>\n",
       "      <td>L_32_R_4_M_3_MR_5_MM_uniform_T_0_02_LW_4_0_2_0_1_0_20211023_233141_820550_AAAA+_step_00496_dldesign_1_relax_0001_rank_1_relax_20220103_171105_507088_permute_rank_1_relax.pdb</td>\n",
       "      <td>/home/drhicks1/af2_cyclic_repeat_proteins/20220119_pocket_hull/L_32_R_4_M_3_MR_5_MM_uniform_T_0_02_LW_4_0_2_0_1_0_20211023_233141_820550_AAAA+_step_00496_dldesign_1_relax_0001_rank_1_relax_20220103_171105_507088_permute_rank_1_relax.pos</td>\n",
       "      <td>128.0</td>\n",
       "      <td>4-HHHHHHHH_4-735</td>\n",
       "      <td>4/HHHHHHHH_4_735/</td>\n",
       "      <td>/home/linnaan/New_AF2_scaffolds/resampled_pseudocycles/PSSM/4/HHHHHHHH_4_735/L_32_R_4_M_3_MR_5_MM_uniform_T_0_02_LW_4_0_2_0_1_0_20211023_233141_820550_AAAA+_step_00496_dldesign_1_relax_0001_rank_1_relax_20220103_171105_507088_permute_rank_1_relax_dldesign_pbias.pssm</td>\n",
       "      <td>/home/linnaan/New_AF2_scaffolds/resampled_pseudocycles/PSSM/4/HHHHHHHH_4_735/L_32_R_4_M_3_MR_5_MM_uniform_T_0_02_LW_4_0_2_0_1_0_20211023_233141_820550_AAAA+_step_00496_dldesign_1_relax_0001_rank_1_relax_20220103_171105_507088_permute_rank_1_relax_dldesign_nobias.pssm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>-188.014</td>\n",
       "      <td>-515.873</td>\n",
       "      <td>76.572</td>\n",
       "      <td>352.040</td>\n",
       "      <td>...</td>\n",
       "      <td>L_30_R_3_M_5_MR_5_MM_uniform_T_0_02_LW_4_0_2_0_1_0_20211022_230901_908256_AAA+_step_00497_dldesign_4_relax_0001_rank_1_relax.pdb</td>\n",
       "      <td>3/LELELELELELEL_3/files.list</td>\n",
       "      <td>3/EEEEEE_3/197.list</td>\n",
       "      <td>L_30_R_3_M_5_MR_5_MM_uniform_T_0_02_LW_4_0_2_0_1_0_20211022_230901_908256_AAA+_step_00497_dldesign_4_relax_0001_rank_1_relax.pdb</td>\n",
       "      <td>/home/drhicks1/af2_cyclic_repeat_proteins/20220119_pocket_hull/L_30_R_3_M_5_MR_5_MM_uniform_T_0_02_LW_4_0_2_0_1_0_20211022_230901_908256_AAA+_step_00497_dldesign_4_relax_0001_rank_1_relax.pos</td>\n",
       "      <td>90.0</td>\n",
       "      <td>3-EEEEEE_3-197</td>\n",
       "      <td>3/EEEEEE_3_197/</td>\n",
       "      <td>/home/linnaan/New_AF2_scaffolds/resampled_pseudocycles/PSSM/3/EEEEEE_3_197/L_30_R_3_M_5_MR_5_MM_uniform_T_0_02_LW_4_0_2_0_1_0_20211022_230901_908256_AAA+_step_00497_dldesign_4_relax_0001_rank_1_relax_dldesign_pbias.pssm</td>\n",
       "      <td>/home/linnaan/New_AF2_scaffolds/resampled_pseudocycles/PSSM/3/EEEEEE_3_197/L_30_R_3_M_5_MR_5_MM_uniform_T_0_02_LW_4_0_2_0_1_0_20211022_230901_908256_AAA+_step_00497_dldesign_4_relax_0001_rank_1_relax_dldesign_nobias.pssm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>-239.014</td>\n",
       "      <td>-492.766</td>\n",
       "      <td>76.636</td>\n",
       "      <td>367.920</td>\n",
       "      <td>...</td>\n",
       "      <td>L_24_R_4_M_3_MR_5_MM_uniform_T_0_02_LW_4_0_2_0_1_0_20211024_154223_597527_AAAA+_step_00446_dldesign_2_relax_0001_rank_1_relax.pdb</td>\n",
       "      <td>4/LELELELELELELELELEL_4/files.list</td>\n",
       "      <td>4/EEEEEEE_4/11.list</td>\n",
       "      <td>L_24_R_4_M_3_MR_5_MM_uniform_T_0_02_LW_4_0_2_0_1_0_20211024_154223_597527_AAAA+_step_00446_dldesign_2_relax_0001_rank_1_relax.pdb</td>\n",
       "      <td>/home/drhicks1/af2_cyclic_repeat_proteins/20220119_pocket_hull/L_24_R_4_M_3_MR_5_MM_uniform_T_0_02_LW_4_0_2_0_1_0_20211024_154223_597527_AAAA+_step_00446_dldesign_2_relax_0001_rank_1_relax.pos</td>\n",
       "      <td>96.0</td>\n",
       "      <td>4-EEEEEEE_4-11</td>\n",
       "      <td>4/EEEEEEE_4_11/</td>\n",
       "      <td>/home/linnaan/New_AF2_scaffolds/resampled_pseudocycles/PSSM/4/EEEEEEE_4_11/L_24_R_4_M_3_MR_5_MM_uniform_T_0_02_LW_4_0_2_0_1_0_20211024_154223_597527_AAAA+_step_00446_dldesign_2_relax_0001_rank_1_relax_dldesign_pbias.pssm</td>\n",
       "      <td>/home/linnaan/New_AF2_scaffolds/resampled_pseudocycles/PSSM/4/EEEEEEE_4_11/L_24_R_4_M_3_MR_5_MM_uniform_T_0_02_LW_4_0_2_0_1_0_20211024_154223_597527_AAAA+_step_00446_dldesign_2_relax_0001_rank_1_relax_dldesign_nobias.pssm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  Unnamed: 0.1.1.1  \\\n",
       "0           0             0               2                 2   \n",
       "1           1             1               4                 4   \n",
       "2           2             2               5                 5   \n",
       "3           3             3               7                 7   \n",
       "4           4             4               8                 8   \n",
       "\n",
       "   Unnamed: 0.1.1.1.1  Unnamed: 0.1.1.1.1.1    score   fa_atr   fa_rep  \\\n",
       "0                   2                     2 -305.763 -948.172  155.222   \n",
       "1                   4                     4 -253.208 -880.858  121.295   \n",
       "2                   5                     5 -245.363 -776.541   89.400   \n",
       "3                   7                     7 -188.014 -515.873   76.572   \n",
       "4                   8                     8 -239.014 -492.766   76.636   \n",
       "\n",
       "    fa_sol  ...  \\\n",
       "0  715.014  ...   \n",
       "1  707.958  ...   \n",
       "2  650.947  ...   \n",
       "3  352.040  ...   \n",
       "4  367.920  ...   \n",
       "\n",
       "                                                                                                                 name_before_permute  \\\n",
       "0   L_50_R_3_M_4_MR_5_MM_uniform_T_0_02_LW_4_0_2_0_1_0_20211031_192628_612107_AAA+_step_00469_dldesign_5_relax_0001_rank_1_relax.pdb   \n",
       "1  L_36_R_4_M_4_MR_5_MM_uniform_T_0_02_LW_4_0_2_0_1_0_20211024_005219_391887_AAAA+_step_00492_dldesign_2_relax_0001_rank_1_relax.pdb   \n",
       "2  L_32_R_4_M_3_MR_5_MM_uniform_T_0_02_LW_4_0_2_0_1_0_20211023_233141_820550_AAAA+_step_00496_dldesign_1_relax_0001_rank_1_relax.pdb   \n",
       "3   L_30_R_3_M_5_MR_5_MM_uniform_T_0_02_LW_4_0_2_0_1_0_20211022_230901_908256_AAA+_step_00497_dldesign_4_relax_0001_rank_1_relax.pdb   \n",
       "4  L_24_R_4_M_3_MR_5_MM_uniform_T_0_02_LW_4_0_2_0_1_0_20211024_154223_597527_AAAA+_step_00446_dldesign_2_relax_0001_rank_1_relax.pdb   \n",
       "\n",
       "              dssp_bin_before_permute                cluster  \\\n",
       "0        3/LHLHLHLHLHLHL_3/files.list     3/HHHHHH_3/62.list   \n",
       "1  4/LHLHLHLHLHLHLHLHLHL_4/files.list   4/HHHHHHHH_4/21.list   \n",
       "2    4/LHLHLHLHLHLHLHLHL_4/files.list  4/HHHHHHHH_4/735.list   \n",
       "3        3/LELELELELELEL_3/files.list    3/EEEEEE_3/197.list   \n",
       "4  4/LELELELELELELELELEL_4/files.list    4/EEEEEEE_4/11.list   \n",
       "\n",
       "                                                                                                                                                                            pdb1  \\\n",
       "0                                               L_50_R_3_M_4_MR_5_MM_uniform_T_0_02_LW_4_0_2_0_1_0_20211031_192628_612107_AAA+_step_00469_dldesign_5_relax_0001_rank_1_relax.pdb   \n",
       "1  L_36_R_4_M_4_MR_5_MM_uniform_T_0_02_LW_4_0_2_0_1_0_20211024_005219_391887_AAAA+_step_00492_dldesign_2_relax_0001_rank_1_relax_20220103_171107_923767_permute_rank_1_relax.pdb   \n",
       "2  L_32_R_4_M_3_MR_5_MM_uniform_T_0_02_LW_4_0_2_0_1_0_20211023_233141_820550_AAAA+_step_00496_dldesign_1_relax_0001_rank_1_relax_20220103_171105_507088_permute_rank_1_relax.pdb   \n",
       "3                                               L_30_R_3_M_5_MR_5_MM_uniform_T_0_02_LW_4_0_2_0_1_0_20211022_230901_908256_AAA+_step_00497_dldesign_4_relax_0001_rank_1_relax.pdb   \n",
       "4                                              L_24_R_4_M_3_MR_5_MM_uniform_T_0_02_LW_4_0_2_0_1_0_20211024_154223_597527_AAAA+_step_00446_dldesign_2_relax_0001_rank_1_relax.pdb   \n",
       "\n",
       "                                                                                                                                                                                                                                posfile_by_hull  \\\n",
       "0                                               /home/drhicks1/af2_cyclic_repeat_proteins/20220119_pocket_hull/L_50_R_3_M_4_MR_5_MM_uniform_T_0_02_LW_4_0_2_0_1_0_20211031_192628_612107_AAA+_step_00469_dldesign_5_relax_0001_rank_1_relax.pos   \n",
       "1  /home/drhicks1/af2_cyclic_repeat_proteins/20220119_pocket_hull/L_36_R_4_M_4_MR_5_MM_uniform_T_0_02_LW_4_0_2_0_1_0_20211024_005219_391887_AAAA+_step_00492_dldesign_2_relax_0001_rank_1_relax_20220103_171107_923767_permute_rank_1_relax.pos   \n",
       "2  /home/drhicks1/af2_cyclic_repeat_proteins/20220119_pocket_hull/L_32_R_4_M_3_MR_5_MM_uniform_T_0_02_LW_4_0_2_0_1_0_20211023_233141_820550_AAAA+_step_00496_dldesign_1_relax_0001_rank_1_relax_20220103_171105_507088_permute_rank_1_relax.pos   \n",
       "3                                               /home/drhicks1/af2_cyclic_repeat_proteins/20220119_pocket_hull/L_30_R_3_M_5_MR_5_MM_uniform_T_0_02_LW_4_0_2_0_1_0_20211022_230901_908256_AAA+_step_00497_dldesign_4_relax_0001_rank_1_relax.pos   \n",
       "4                                              /home/drhicks1/af2_cyclic_repeat_proteins/20220119_pocket_hull/L_24_R_4_M_3_MR_5_MM_uniform_T_0_02_LW_4_0_2_0_1_0_20211024_154223_597527_AAAA+_step_00446_dldesign_2_relax_0001_rank_1_relax.pos   \n",
       "\n",
       "    nres        short_name   indi_cluster_dir  \\\n",
       "0  150.0     3-HHHHHH_3-62     3/HHHHHH_3_62/   \n",
       "1  144.0   4-HHHHHHHH_4-21   4/HHHHHHHH_4_21/   \n",
       "2  128.0  4-HHHHHHHH_4-735  4/HHHHHHHH_4_735/   \n",
       "3   90.0    3-EEEEEE_3-197    3/EEEEEE_3_197/   \n",
       "4   96.0    4-EEEEEEE_4-11    4/EEEEEEE_4_11/   \n",
       "\n",
       "                                                                                                                                                                                                                                                            polar_bias_pssm_f  \\\n",
       "0                                                  /home/linnaan/New_AF2_scaffolds/resampled_pseudocycles/PSSM/3/HHHHHH_3_62/L_50_R_3_M_4_MR_5_MM_uniform_T_0_02_LW_4_0_2_0_1_0_20211031_192628_612107_AAA+_step_00469_dldesign_5_relax_0001_rank_1_relax_dldesign_pbias.pssm   \n",
       "1   /home/linnaan/New_AF2_scaffolds/resampled_pseudocycles/PSSM/4/HHHHHHHH_4_21/L_36_R_4_M_4_MR_5_MM_uniform_T_0_02_LW_4_0_2_0_1_0_20211024_005219_391887_AAAA+_step_00492_dldesign_2_relax_0001_rank_1_relax_20220103_171107_923767_permute_rank_1_relax_dldesign_pbias.pssm   \n",
       "2  /home/linnaan/New_AF2_scaffolds/resampled_pseudocycles/PSSM/4/HHHHHHHH_4_735/L_32_R_4_M_3_MR_5_MM_uniform_T_0_02_LW_4_0_2_0_1_0_20211023_233141_820550_AAAA+_step_00496_dldesign_1_relax_0001_rank_1_relax_20220103_171105_507088_permute_rank_1_relax_dldesign_pbias.pssm   \n",
       "3                                                 /home/linnaan/New_AF2_scaffolds/resampled_pseudocycles/PSSM/3/EEEEEE_3_197/L_30_R_3_M_5_MR_5_MM_uniform_T_0_02_LW_4_0_2_0_1_0_20211022_230901_908256_AAA+_step_00497_dldesign_4_relax_0001_rank_1_relax_dldesign_pbias.pssm   \n",
       "4                                                /home/linnaan/New_AF2_scaffolds/resampled_pseudocycles/PSSM/4/EEEEEEE_4_11/L_24_R_4_M_3_MR_5_MM_uniform_T_0_02_LW_4_0_2_0_1_0_20211024_154223_597527_AAAA+_step_00446_dldesign_2_relax_0001_rank_1_relax_dldesign_pbias.pssm   \n",
       "\n",
       "                                                                                                                                                                                                                                                                no_bias_pssm_f  \n",
       "0                                                  /home/linnaan/New_AF2_scaffolds/resampled_pseudocycles/PSSM/3/HHHHHH_3_62/L_50_R_3_M_4_MR_5_MM_uniform_T_0_02_LW_4_0_2_0_1_0_20211031_192628_612107_AAA+_step_00469_dldesign_5_relax_0001_rank_1_relax_dldesign_nobias.pssm  \n",
       "1   /home/linnaan/New_AF2_scaffolds/resampled_pseudocycles/PSSM/4/HHHHHHHH_4_21/L_36_R_4_M_4_MR_5_MM_uniform_T_0_02_LW_4_0_2_0_1_0_20211024_005219_391887_AAAA+_step_00492_dldesign_2_relax_0001_rank_1_relax_20220103_171107_923767_permute_rank_1_relax_dldesign_nobias.pssm  \n",
       "2  /home/linnaan/New_AF2_scaffolds/resampled_pseudocycles/PSSM/4/HHHHHHHH_4_735/L_32_R_4_M_3_MR_5_MM_uniform_T_0_02_LW_4_0_2_0_1_0_20211023_233141_820550_AAAA+_step_00496_dldesign_1_relax_0001_rank_1_relax_20220103_171105_507088_permute_rank_1_relax_dldesign_nobias.pssm  \n",
       "3                                                 /home/linnaan/New_AF2_scaffolds/resampled_pseudocycles/PSSM/3/EEEEEE_3_197/L_30_R_3_M_5_MR_5_MM_uniform_T_0_02_LW_4_0_2_0_1_0_20211022_230901_908256_AAA+_step_00497_dldesign_4_relax_0001_rank_1_relax_dldesign_nobias.pssm  \n",
       "4                                                /home/linnaan/New_AF2_scaffolds/resampled_pseudocycles/PSSM/4/EEEEEEE_4_11/L_24_R_4_M_3_MR_5_MM_uniform_T_0_02_LW_4_0_2_0_1_0_20211024_154223_597527_AAAA+_step_00446_dldesign_2_relax_0001_rank_1_relax_dldesign_nobias.pssm  \n",
       "\n",
       "[5 rows x 108 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this contains 1 scaffold from each cluster, no filter on scaffold quality.\n",
    "# can change with more knowledge\n",
    "# pseudocycle lists\n",
    "# ref: https://doi.org/10.1038/s41594-023-01112-6\n",
    "#      https://github.com/LAnAlchemist/Psedocycles_NSMB.git\n",
    "scaffold_df = pd.read_csv('finalist_21k_info_v220106_clustered_hullpos_forDock_cleaned_155aa.csv')\n",
    "print(len(scaffold_df))\n",
    "scaffold_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_hb_filters(atm_list,scorefxn):\n",
    "    filters,protocols = [],[]\n",
    "    for atm in atm_list:\n",
    "        filters.append(f'<SimpleHbondsToAtomFilter name=\"hb_to_{atm}\" n_partners=\"1\" hb_e_cutoff=\"-0.3\" target_atom_name=\"{atm}\" res_num=\"%%ligand_res_number%%\" scorefxn=\"{scorefxn}\" confidence=\"0\"/>')\n",
    "        protocols.append(f'<Add filter=\"hb_to_{atm}\"/>')\n",
    "    return filters,protocols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot2pandas(df1,df2,features,legend1='sel',legend2='all',ncols=3):\n",
    "    nrows = math.ceil(len(features) / ncols)\n",
    "    (fig, axs) = plt.subplots(ncols=ncols, nrows=nrows, figsize=[4*ncols,3*nrows])\n",
    "    axs = axs.reshape(-1)\n",
    "    for (i, metric) in enumerate(features):\n",
    "        sns.distplot(df1[metric].dropna(), ax=axs[i],label=legend1).legend()\n",
    "        sns.distplot(df2[metric].dropna(), ax=axs[i],label=legend2).legend()\n",
    "    sns.despine()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.RIFgen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rifgen_dir = f'{scratch_dir}1_rifgen/'\n",
    "os.makedirs(rifgen_dir,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n,lig in enumerate(ligands):\n",
    "    if (lig == 'T44'):\n",
    "        os.makedirs(f'{rifgen_dir}{lig}_rifgen/',exist_ok=True)\n",
    "         # change here to your RIFGen path\n",
    "        temp_requirements = './toolkits/require_hb.txt'\n",
    "        dst_requirements = f'{rifgen_dir}{lig}_rifgen/require_hb.txt'\n",
    "        copyfile(temp_requirements,dst_requirements)\n",
    "        hbond_requirements = [f'{n+1} HBOND {atm} 1' for n,atm in enumerate(ligands[lig][4].split(','))]\n",
    "        hbond_requirements = '\\n'.join(hbond_requirements)\n",
    "        sed_inplace(dst_requirements, '__REQUIREMENTS__', hbond_requirements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Manual change `require_hb.txt` file for changing requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make directories\n",
    "rifgen_dir = f'{scratch_dir}1_rifgen/'\n",
    "os.makedirs(rifgen_dir,exist_ok=True)\n",
    "for n,lig in enumerate(ligands):\n",
    "    if (lig == 'T44'):\n",
    "        os.makedirs(f'{rifgen_dir}{lig}_rifgen/',exist_ok=True)\n",
    "        for rotamer in ligands[lig][2]:\n",
    "            rotamer_name = os.path.basename(rotamer).replace('.pdb','')\n",
    "            rotamer_rifgen_dir = f'{rifgen_dir}{lig}_rifgen/{rotamer_name}/'\n",
    "            os.makedirs(rotamer_rifgen_dir,exist_ok=True)\n",
    "            os.makedirs(rotamer_rifgen_dir+'/cache',exist_ok=True)\n",
    "            temp_requirements = f'{rifgen_dir}{lig}_rifgen/require_hb.txt'\n",
    "            temp_flag = '1st_SC_screen/rifgen_no_req.flags_substitutable'\n",
    "            # change temp_qsub to your own submission file\n",
    "            temp_qsub = '1st_SC_screen/qsub.sh'\n",
    "            dst_requirements = f'{rotamer_rifgen_dir}require_hb.txt'\n",
    "            dst_flag = f'{rotamer_rifgen_dir}rifgen.flags'\n",
    "            dst_qsub = f'{rotamer_rifgen_dir}qsub.sh'\n",
    "            copyfile(temp_flag,dst_flag)\n",
    "            sed_inplace(dst_flag, '__OUTDIR__', f'{rotamer_rifgen_dir}output')\n",
    "            sed_inplace(dst_flag, '__PDB__', rotamer)\n",
    "            sed_inplace(dst_flag, '__PARAMS__', ligands[lig][1]) #use ref2015params\n",
    "            sed_inplace(dst_flag, '__ligand3letter__', lig)\n",
    "            # add this if your computing system has specific locations for cache, need 1-2 G\n",
    "            # by default, we create individual cache for each dock, it will take a lot of space, but\n",
    "            # it prevents one failed job fail other jobs.\n",
    "            #sed_inplace(dst_flag, '__LIG_CACHE__', f'{rifgen_dir}{lig}_rifgen/cache_dir')\n",
    "            copyfile(temp_qsub,dst_qsub)\n",
    "            copyfile(temp_requirements,dst_requirements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test, if good, submit. You should get a few Gb of rif output/ for each rotamer.\n",
    "for lig in ligands:\n",
    "    if (lig == 'T44'): # or (lig == 'DIG')\n",
    "        for rotamer in ligands[lig][2]:\n",
    "            rotamer_name = os.path.basename(rotamer).replace('.pdb','')\n",
    "            rotamer_rifgen_dir = f'{rifgen_dir}{lig}_rifgen/{rotamer_name}/'\n",
    "            if os.path.isfile(rotamer_rifgen_dir+'rifgen.log') == False:\n",
    "                os.chdir(rotamer_rifgen_dir)\n",
    "                subprocess.check_call(f'sbatch qsub.sh',shell=True)\n",
    "                print(f'submit {rotamer_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. RIFdock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Did not turn off Ala for rifdock. Found not important at scaffold selection stage.\n",
    "rifdock_dir = f'{scratch_dir}2_rifdock/'\n",
    "os.makedirs(rifdock_dir,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate individual flags\n",
    "for n,lig in enumerate(ligands):\n",
    "    if (lig=='T44'):\n",
    "        for rotamer in ligands[lig][2]:\n",
    "            rotamer_name = os.path.basename(rotamer).replace('.pdb','')\n",
    "            indi_rot_dock_dir = f'{rifdock_dir}{lig}_rifdock/{rotamer_name}/'\n",
    "            os.makedirs(f'{rifdock_dir}{lig}_rifdock/cache',exist_ok=True) #not needed. Rifdock create cache\n",
    "            os.makedirs(indi_rot_dock_dir,exist_ok=True)\n",
    "            temp_flag = '1st_SC_screen/rifdock_tail.flags'\n",
    "            dst_flag = f'{indi_rot_dock_dir}rifdock.flags'\n",
    "            copyfile(temp_flag,dst_flag)\n",
    "            sed_inplace(dst_flag, '__PDBOUT__', '10')\n",
    "            sed_inplace(dst_flag, '__REQUIREMENTS__', ligands[lig][3])\n",
    "            sed_inplace(dst_flag, '__SCORECUTOFF__', str(int(0*(len(ligands[lig][3].split(','))))))\n",
    "            rifgen_log = f'{scratch_dir}1_rifgen/{lig}_rifgen/{rotamer_name}/rifgen.log'\n",
    "            sed_inplace(dst_flag, '__RIFGENOUT__', get_flags(rifgen_log,False))\n",
    "            sed_inplace(dst_flag, '__CACHE_DIR__', f'{rifdock_dir}{lig}_rifdock/cache')\n",
    "            temp_qsub = '1st_SC_screen/rifdock_qsub.sh'\n",
    "            dst_qsub = f'{indi_rot_dock_dir}qsub.sh'\n",
    "            copyfile(temp_qsub,dst_qsub)\n",
    "# Manually change each flags if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate docking commands\n",
    "for n,lig in enumerate(ligands):\n",
    "    if (lig=='T44'):\n",
    "        cmds=[]\n",
    "        for rotamer in ligands[lig][2]:\n",
    "            rotamer_name = os.path.basename(rotamer).replace('.pdb','')\n",
    "            indi_rot_dock_dir = f'{rifdock_dir}{lig}_rifdock/{rotamer_name}/'\n",
    "            for i,(j,row) in enumerate(scaffold_df.iterrows()):\n",
    "                if i >= 0:\n",
    "                    scaffold = row['path']\n",
    "                    cluster = row['cluster']\n",
    "                    indi_cluster_dir = indi_rot_dock_dir + '/'.join(cluster.split('/')[0:2]) + \\\n",
    "                                       '_' + cluster.split('/')[2].replace('.list','') + '/'\n",
    "                    os.makedirs(indi_cluster_dir,exist_ok=True)\n",
    "                    os.chdir(indi_cluster_dir)\n",
    "                    temp_flag = f'{rifdock_dir}{lig}_rifdock/{rotamer_name}/rifdock.flags'\n",
    "                    copyfile(temp_flag,'rifdock.flags')\n",
    "                    temp_flag = f'{rifdock_dir}{lig}_rifdock/{rotamer_name}/qsub.sh'\n",
    "                    copyfile(temp_flag,'qsub.sh')\n",
    "                    fp = open('SCAFFOLD.list','w')\n",
    "                    fp.write(scaffold)\n",
    "                    fp.close()\n",
    "                    fp = open('POSFILE.list','w')\n",
    "                    fp.write(home_dir+row['posfile_by_hull']) # you may need to change this based on how your scripts is set\n",
    "                    fp.close()\n",
    "                    if len(glob.glob(f'{indi_cluster_dir}out/*all.dok*')) == 0:\n",
    "                        cmds.append(f'cd {indi_cluster_dir}; bash qsub.sh')\n",
    "        fp = open(f'{rifdock_dir}{lig}_rifdock/{lig}_1strifdock_PC','w')\n",
    "        fp.write('\\n'.join(cmds))\n",
    "        fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit\n",
    "for n,lig in enumerate(ligands):\n",
    "    if (lig=='T44'):\n",
    "        indi_dock_dir = f'{rifdock_dir}{lig}_rifdock/'\n",
    "        os.chdir(indi_dock_dir)\n",
    "        cmd_f = f'{lig}_1strifdock_PC'\n",
    "        make_submit_file(cmds=cmd_f,submitfile=f'{cmd_f}.submit.sh',\n",
    "            time='5:00:00',group_size=80,logsfolder='logs',cpus=2,mem='20g')\n",
    "        subprocess.check_call(f'sbatch {cmd_f}.submit.sh',shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count docks\n",
    "docks = {}\n",
    "total_silents = 0\n",
    "for n,lig in enumerate(ligands):\n",
    "    if (lig=='T44'):\n",
    "        docks[lig]={}\n",
    "        lig_rifdock_dir = f'{rifdock_dir}{lig}_rifdock/'\n",
    "        for rotamer in ligands[lig][2]:\n",
    "            docks_num = 0\n",
    "            rotamer_name = os.path.basename(rotamer).replace('.pdb','')\n",
    "            docks[lig][rotamer_name] =[]\n",
    "            success_cluster = 0\n",
    "            indi_rot_dock_dir = f'{lig_rifdock_dir}{rotamer_name}/'\n",
    "            for i,(j,row) in enumerate(scaffold_df.iterrows()):\n",
    "                if i >= 0:\n",
    "                    cluster = row['cluster']\n",
    "                    indi_cluster_dir = indi_rot_dock_dir + row['indi_cluster_dir']\n",
    "                    all_doks = glob.glob(f'{indi_cluster_dir}out/*all.dok*')\n",
    "                    if len(all_doks) >= 0:\n",
    "                        if len(glob.glob(f'{indi_cluster_dir}out/*.silent')) > 0:\n",
    "                            success_cluster += 1\n",
    "                            for all_dok in all_doks:\n",
    "                                with open(all_dok,'r') as f: \n",
    "                                    docks_num += len(f.readlines())\n",
    "                            docks[lig][rotamer_name] += glob.glob(f'{indi_cluster_dir}out/*.silent')\n",
    "            print(f'{lig} {rotamer_name} got docks: {docks_num} from {success_cluster} clusters\\n__________________')\n",
    "            total_silents += success_cluster\n",
    "        with open(f\"{lig_rifdock_dir}dock_list.json\", \"w\") as outfile:\n",
    "            json.dump(docks[lig], outfile)\n",
    "        print(f'{lig} generated {total_silents} stotal_silents in total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## !!!Remove cache direcotry and logs directory, they take lots of spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (optional) Can write checkpoint file at rifdock directory to control which part of clusters go into design. Useful if just want to test some cluster for design or do not want to repeat design for some clusters\n",
    "`checkpoint_f = f'{scratch_dir}rifdock/{lig}_rifdock/{rotamer_name}/already_docked_checkpoint'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3_1. Predictor1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use quick predictor (method1) to design all docks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare local version of flag and xml\n",
    "tmp_protocol = '1st_SC_screen/FastPredictor_v2_talaris_ligand_3.xml'\n",
    "tmp_flag = '1st_SC_screen/flags_rescore_talaris_1'\n",
    "os.makedirs(f'{scratch_dir}3_prediction/',exist_ok=True)\n",
    "for n,lig in enumerate(ligands):\n",
    "    if (lig=='T44'):\n",
    "        design_dir = f'{scratch_dir}3_prediction/{lig}_prediction/'\n",
    "        os.makedirs(design_dir,exist_ok=True)\n",
    "        dst_protocol = design_dir + f'FastPredictor_v2_talaris_ligand_3.xml'\n",
    "        copyfile(tmp_protocol,dst_protocol)\n",
    "        fiters,protocols = generate_hb_filters(ligands[lig][4].split(','),'sfxn')\n",
    "#         sed_inplace(dst_protocol,'__HBFILTER__','\\n'.join(fiters))\n",
    "#         sed_inplace(dst_protocol,'__HBFILTERPROTOCOL__','\\n'.join(protocols))\n",
    "        for rotamer in ligands[lig][2]:\n",
    "            rotamer_name = os.path.basename(rotamer).replace('.pdb','')\n",
    "            indi_rot_design_dir = f'{design_dir}{rotamer_name}/'\n",
    "            os.makedirs(indi_rot_design_dir,exist_ok=True)\n",
    "            dst_flag = indi_rot_design_dir + 'flags_rescore_talaris_1'\n",
    "            copyfile(tmp_flag,dst_flag)\n",
    "            sed_inplace(dst_flag,'__PARAMS__',ligands[lig][1]) #still use ref2015 since we are using talaris\n",
    "#             sed_inplace(dst_flag,'__SUFFIX__',f'_{rotamer_name}')\n",
    "            indi_dst_protocol = indi_rot_design_dir + f'FastPredictor_v2_talaris_ligand_3.xml'\n",
    "            copyfile(dst_protocol,indi_dst_protocol)\n",
    "# make changes to local version of flag and dock xml if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cmd generation option 1: generate using Jupyter Notebook\n",
    "TEST = False # if test, deposite PDB, if not, score only\n",
    "# Generate individual design commands\n",
    "ROSETTA = '/software/rosetta/latest/bin/rosetta_scripts.hdf5.linuxgccrelease' # change to your rosetta path\n",
    "for n,lig in enumerate(ligands):\n",
    "    if (lig=='T44'):\n",
    "        design_dir = f'{scratch_dir}3_prediction/{lig}_prediction/'\n",
    "        os.makedirs(design_dir,exist_ok=True)\n",
    "        cmds = []\n",
    "        os.chdir(design_dir)\n",
    "        for rotamer in ligands[lig][2]:\n",
    "            rotamer_name = os.path.basename(rotamer).replace('.pdb','')\n",
    "            print(f'For {rotamer_name}:________________________________')\n",
    "            already_designed = []\n",
    "            checkpoint_f = f'{scratch_dir}2_rifdock/{lig}_rifdock/{rotamer_name}/already_docked_checkpoint'\n",
    "            if os.path.isfile(checkpoint_f):\n",
    "                fp = open(checkpoint_f,'r')\n",
    "                for line in fp:\n",
    "                    already_designed.append(line.rstrip())\n",
    "                fp.close()\n",
    "            print(f'already designed {len(already_designed)}')\n",
    "            protocol = 'FastPredictor_v2_talaris_ligand_3.xml'\n",
    "            flag = 'flags_rescore_talaris_1'\n",
    "            for n,dock in enumerate(docks[lig][rotamer_name]):\n",
    "                if n >= 0:\n",
    "                    indi_cluster_dir = f'{rotamer_name}/'+ dock.split('/')[-4]+\\\n",
    "                                       '/'+dock.split('/')[-3] + '/'\n",
    "                    cluster_name = '_'.join(('/'.join(dock.split('/')[-4:-2])).split('_')[:-1])+'/'+\\\n",
    "                                 dock.split('/')[-3].split('_')[-1]+'.list'\n",
    "                    if cluster_name not in already_designed:\n",
    "                        os.makedirs(indi_cluster_dir,exist_ok=True)\n",
    "                        lig_num = int(scaffold_df.loc[scaffold_df['cluster']==cluster_name,'nres'].values[0])+1\n",
    "                        if TEST: \n",
    "                            if n < 1:\n",
    "                                cmds.append(f'cd {design_dir}{indi_cluster_dir}; {ROSETTA} -parser:protocol ../../../{protocol} '+\\\n",
    "                                            f'@../../{flag} -in:file:silent {dock} ' + \\\n",
    "        #                                     f'-out:file:write_pdb_parametric_info True ' + \\\n",
    "#                                             f'-out:file:score_only ' +\\\n",
    "                                            f'-parser:script_vars ligand_res_number={lig_num}')\n",
    "                            else:\n",
    "                                break\n",
    "                        else:\n",
    "                            cmds.append(f'cd {design_dir}{indi_cluster_dir}; {ROSETTA} -parser:protocol ../../../{protocol} '+\\\n",
    "                                        f'@../../{flag} -in:file:silent {dock} ' + \\\n",
    "                                        f'-out:file:score_only predictor.sc ' +\\\n",
    "                                        f'-parser:script_vars ligand_res_number={lig_num}')\n",
    "        cmd_f = f'{lig}_1stpredictor1'\n",
    "        with open(cmd_f,'w') as f:\n",
    "            f.write('\\n'.join(cmds))\n",
    "        print(f'write {len(cmds)} design commands')\n",
    "        SUBMIT = False\n",
    "        make_submit_file(cmds=cmd_f,\n",
    "                submitfile=f'{cmd_f}.submit.sh',time='3:00:00',group_size=500,logsfolder='logs',cpus=1,\n",
    "                mem='1g') ## SSpred usage save cache which will create error if visited too often. \n",
    "        if SUBMIT:\n",
    "            subprocess.check_call(f'sbatch {cmd_f}.submit.sh',shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### What's most optimal allocation of each step?\n",
    "- rifdock: 20gb, 2CPU\n",
    "- predictor: 1 gb, 1cpu\n",
    "- design: 3gb. 1cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Collect results\n",
    "designs = {}\n",
    "for n,lig in enumerate(ligands):\n",
    "    if (lig == 'T44'):\n",
    "        designs[lig]={}\n",
    "        design_dir = f'{scratch_dir}3_prediction/{lig}_prediction/'\n",
    "        total_num = 0\n",
    "        for rotamer in ligands[lig][2]:\n",
    "            success = 0\n",
    "            rotamer_name = os.path.basename(rotamer).replace('.pdb','')\n",
    "            indi_rot_design_dir = f'{design_dir}{rotamer_name}/'\n",
    "            designs[lig][rotamer_name] =[]\n",
    "            for i,(j,row) in enumerate(scaffold_df.iterrows()):\n",
    "                if i >= 0:\n",
    "                    cluster =row['cluster']\n",
    "                    indi_cluster_dir = indi_rot_design_dir + row['indi_cluster_dir']\n",
    "                    predictor_sc_f = glob.glob(f'{indi_cluster_dir}predictor.sc')\n",
    "                    if len(predictor_sc_f) > 0:\n",
    "                        success += 1\n",
    "                        designs[lig][rotamer_name] += predictor_sc_f\n",
    "            print(f'{lig} {rotamer_name} from {success} clusters got designs: {len(designs[lig][rotamer_name])}\\n__________________')\n",
    "            total_num += len(designs[lig][rotamer_name])\n",
    "        print(f'[SUM] {lig} got predictor scs in total: {total_num}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n,lig in enumerate(ligands):\n",
    "    if (lig == 'T44'):\n",
    "        df_list = []\n",
    "        design_dir = f'{scratch_dir}3_prediction/{lig}_prediction/'\n",
    "        for rotamer in ligands[lig][2]:\n",
    "            rotamer_name = os.path.basename(rotamer).replace('.pdb','')\n",
    "            for i,sc in enumerate(designs[lig][rotamer_name]):\n",
    "                if i >= 0:\n",
    "                    indi_df = pd.read_csv(sc,header=1,delim_whitespace=True)\n",
    "                    indi_df['indi_cluster_dir'] = '/'.join(sc.split('/')[-3:-1])+'/'\n",
    "                    indi_cluster_dir = '/'.join(sc.split('/')[-3:-1])+'/'\n",
    "                    indi_df['cluster'] = scaffold_df.loc[scaffold_df['indi_cluster_dir']==indi_cluster_dir,'cluster'].values[0]\n",
    "                    indi_df['rotamer'] = rotamer_name\n",
    "                    silent_in = f'{scratch_dir}2_rifdock/{lig}_rifdock/{rotamer_name}/{indi_cluster_dir}out/'+\\\n",
    "                                indi_df.description[0].split('_000000')[0]+'.silent'\n",
    "                    if not os.path.isfile(silent_in):\n",
    "                        print(f'Error {silent_in}')\n",
    "                    indi_df['silent_in'] = silent_in\n",
    "                    \n",
    "                    df_list.append(indi_df)\n",
    "        all_df = pd.concat(df_list)\n",
    "        all_df['name'] = all_df['description'] + '_' + all_df['rotamer']\n",
    "        all_df.to_csv(f'{design_dir}all_predictor.sc')\n",
    "        print(f'{lig} {len(all_df)}') \n",
    "all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalized = True#use figure and numbers to decide the CMS cutoff to use\n",
    "CMS_CUTOFF = {'T44':50/100} #percentile\n",
    "ncols = 3  \n",
    "nrows = math.ceil(len(ligands) / ncols) #because we will also be plotting ROCs  \n",
    "(fig, axs) = plt.subplots(ncols=ncols, nrows=nrows, figsize=[4*ncols,4*nrows]  )  \n",
    "axs = axs.reshape(-1)\n",
    "for n,lig in enumerate(ligands):\n",
    "    if (lig == 'T44'): #(lig == 'APC') or (lig == 'HCY') or \n",
    "        design_dir = f'{scratch_dir}3_prediction/{lig}_prediction/'\n",
    "        all_df = pd.read_csv(f'{design_dir}all_predictor.sc')\n",
    "        all_df = all_df.sort_values(by='contact_molecular_surface',ascending=False)\n",
    "        value = all_df['contact_molecular_surface'].quantile(q=CMS_CUTOFF[lig],interpolation=\"nearest\")\n",
    "        sel_df = all_df[all_df['contact_molecular_surface']>=value]\n",
    "        print(f'{lig} CMS at quantile {CMS_CUTOFF[lig]} has {value}, {len(sel_df)}/{len(all_df)} docks selected')\n",
    "        sns.histplot(data=all_df,x='contact_molecular_surface',label='all',color='blue',ax=axs[n]).set_xlabel(f'{lig} contact_molecular_surface')\n",
    "        sns.histplot(data=sel_df,x='contact_molecular_surface',label='sel',color='orange',ax=axs[n]).set_xlabel(f'{lig} contact_molecular_surface')\n",
    "        axs[n].legend()\n",
    "        if finalized:\n",
    "            sel_df.to_csv(f'{design_dir}sel_for_2ndpredictor.sc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional: extract chosen silent files and remove bad ones, to save space.\n",
    "SUBMIT = True\n",
    "for n,lig in enumerate(ligands):\n",
    "    if (lig == 'T44'): # or (lig == 'EST'): #(lig == 'APC') or (lig == 'HCY')\n",
    "        design_dir = f'{scratch_dir}3_prediction/{lig}_prediction/'\n",
    "        os.chdir(design_dir)\n",
    "        sel_df = pd.read_csv(f'{design_dir}sel_for_2ndpredictor.sc')\n",
    "        cmds = []\n",
    "        for i,silent_f in enumerate(set(list(sel_df['silent_in']))):\n",
    "            if i>=0:\n",
    "                sel_cluster = sel_df[sel_df['silent_in']==silent_f]\n",
    "                tags = ' '.join(list(sel_cluster['description']))\n",
    "                if len(tags) > 0:\n",
    "                    new_silent_f = silent_f.replace('.silent','_sel.silent')\n",
    "                    cmds.append(f'echo \"{tags}\" | silentslice {silent_f} > {new_silent_f}')\n",
    "        cmd_f = f'{lig}_extract_silent'\n",
    "        with open(cmd_f,'w') as fp:\n",
    "            fp.write('\\n'.join(cmds))\n",
    "        make_submit_file(cmds=cmd_f,submitfile=f'{cmd_f}_submit.sh',time='3:00:00',\n",
    "                        group_size=int(len(cmds)/200)+1,logsfolder='logs',cpus=1,mem='1g')\n",
    "        if SUBMIT:\n",
    "            subprocess.check_call(f'sbatch {cmd_f}_submit.sh',shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove original rifdock silent file to save space\n",
    "for n,lig in enumerate(ligands):\n",
    "    if (lig == 'T44'):\n",
    "        start_time = time.time()\n",
    "        cmds = []\n",
    "        design_dir = f'{scratch_dir}2_rifdock/{lig}_rifdock/'\n",
    "        os.chdir(design_dir)\n",
    "        if os.path.isfile(f'{scratch_dir}/3_prediction/{lig}_prediction/sel_for_2ndpredictor.sc'):\n",
    "            with open('dock_list.json','r') as fp:\n",
    "                dock_dic = json.load(fp)\n",
    "            for rotamer_name in dock_dic:\n",
    "                cmds += [f'rm {silent_f}' for silent_f in dock_dic[rotamer_name]]\n",
    "            cmd_f = f'rm_{lig}_orig_silent'\n",
    "            with open(cmd_f,'w') as fp:\n",
    "                fp.write('\\n'.join(cmds))\n",
    "            make_submit_file(cmds=cmd_f,submitfile=f'{cmd_f}.submit.sh',time=\"12:00:00\",\n",
    "                             group_size=int(len(cmds)/10),\n",
    "            logsfolder='logs',cpus=1,mem='1g',)\n",
    "            print(f'wrote for {lig}')\n",
    "            SUBMIT = False\n",
    "            if SUBMIT:\n",
    "                subprocess.check_call(f'sbatch {cmd_f}.submit.sh',shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3_2. Slower predictor to continue predict: old broken beta_nov16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare local version of flag and xml\n",
    "tmp_protocol = '1st_SC_screen/LA_quick_design_select_dock_genpot_2.xml'\n",
    "tmp_flag = '1st_SC_screen/flags_rescore_genpot_1'\n",
    "os.makedirs(f'{scratch_dir}3_prediction_ref2015_oldmethod/',exist_ok=True)\n",
    "for n,lig in enumerate(ligands):\n",
    "    if (lig == 'T44'):# or (lig == 'HCY'):\n",
    "        design_dir = f'{scratch_dir}3_prediction_ref2015_oldmethod/{lig}_prediction/'\n",
    "        os.makedirs(design_dir,exist_ok=True)\n",
    "        dst_protocol = design_dir + f'LA_quick_design_select_dock_genpot_2.xml'\n",
    "        copyfile(tmp_protocol,dst_protocol)\n",
    "        fiters,protocols = generate_hb_filters(ligands[lig][4].split(','),'sfxn')\n",
    "        sed_inplace(dst_protocol,'__HBFILTER__','\\n'.join(fiters))\n",
    "        sed_inplace(dst_protocol,'__HBFILTERPROTOCOL__','\\n'.join(protocols))\n",
    "        for rotamer in ligands[lig][2]:\n",
    "            rotamer_name = os.path.basename(rotamer).replace('.pdb','')\n",
    "            indi_rot_design_dir = f'{design_dir}{rotamer_name}/'\n",
    "            os.makedirs(indi_rot_design_dir,exist_ok=True)\n",
    "            dst_flag = indi_rot_design_dir + 'flags_rescore_genpot_1'\n",
    "            copyfile(tmp_flag,dst_flag)\n",
    "            sed_inplace(dst_flag,'__PARAMS__',ligands[lig][1]) #still use ref2015 since we are using talaris\n",
    "#             sed_inplace(dst_flag,'__SUFFIX__',f'_{rotamer_name}')\n",
    "            indi_dst_protocol = indi_rot_design_dir + f'LA_quick_design_select_dock_genpot_2.xml'\n",
    "            copyfile(design_dir + f'LA_quick_design_select_dock_genpot_2.xml',indi_dst_protocol)\n",
    "# make changes to local version of flag and dock xml if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate individual design commands\n",
    "# change to your Rosetta path\n",
    "ROSETTA = '/software/rosetta/latest/bin/rosetta_scripts.hdf5.linuxgccrelease'\n",
    "for n,lig in enumerate(ligands):\n",
    "    if (lig == 'T44'):# or (lig == 'HCY'):\n",
    "        design_dir = f'{scratch_dir}3_prediction_ref2015_oldmethod/{lig}_prediction/'\n",
    "        sel_df = pd.read_csv(f'{scratch_dir}3_prediction/{lig}_prediction/sel_for_2ndpredictor.sc')\n",
    "        cmds = []\n",
    "        os.chdir(design_dir)\n",
    "        for rotamer in ligands[lig][2]:\n",
    "            rotamer_name = os.path.basename(rotamer).replace('.pdb','')\n",
    "            print(f'For {rotamer_name}:________________________________')\n",
    "            protocol = 'LA_quick_design_select_dock_genpot_2.xml'\n",
    "            flag = 'flags_rescore_genpot_1'\n",
    "            rotamer_sel_df = sel_df[sel_df['rotamer']==rotamer_name]\n",
    "            for n,silent_in in enumerate(list(set(rotamer_sel_df.silent_in))):\n",
    "                if n >= 0:\n",
    "                    indi_silent_df = rotamer_sel_df[rotamer_sel_df['silent_in']==silent_in]\n",
    "                    for indi_cluster_dir in list(set(indi_silent_df.indi_cluster_dir)):\n",
    "                        lig_num = 1+int(scaffold_df.loc[scaffold_df['indi_cluster_dir']==indi_cluster_dir,'nres'].values[0])\n",
    "                        indi_cluster_dir = f'{rotamer_name}/'+ indi_cluster_dir\n",
    "                        os.makedirs(indi_cluster_dir,exist_ok=True)\n",
    "                        sel_silent_in = silent_in.replace('.silent','_sel.silent')\n",
    "                        cmds.append(f'cd {design_dir}{indi_cluster_dir}; {ROSETTA} -parser:protocol '+\\\n",
    "                                    f'../../../{protocol} @../../{flag} -in:file:silent '+\\\n",
    "                                    f'{sel_silent_in} ' + \\\n",
    "                                    f'-out:file:score_only predictor.sc ' +\\\n",
    "                                    f'-parser:script_vars ligand_res_number={lig_num}')\n",
    "        cmd_f = design_dir + f'{lig}_predictor2_cmds'\n",
    "        with open(cmd_f,'w') as fp:\n",
    "            fp.write('\\n'.join(cmds))\n",
    "        make_submit_file(cmds=cmd_f,submitfile=f'{cmd_f}.submit.sh',time=\"3:00:00\",\n",
    "                group_size=50 ,logsfolder='logs',cpus=1,mem='1g',limit_job_to100=False,\n",
    "                needs_gpu=False) ## SSpred usage save cache which will create error if visited too often. \n",
    "        print(f'write {len(cmds)} design commands')\n",
    "        SUBMIT = True\n",
    "        if SUBMIT:\n",
    "            subprocess.check_call(f'sbatch {cmd_f}.submit.sh',shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Collect results\n",
    "designs = {}\n",
    "for n,lig in enumerate(ligands):\n",
    "    if (lig == 'T44'): #or (lig == 'HCY'):\n",
    "        designs[lig]={}\n",
    "        design_dir = f'{scratch_dir}3_prediction_ref2015_oldmethod/{lig}_prediction/'\n",
    "        for rotamer in ligands[lig][2]:\n",
    "            success = 0\n",
    "            rotamer_name = os.path.basename(rotamer).replace('.pdb','')\n",
    "            indi_rot_design_dir = f'{design_dir}{rotamer_name}/'\n",
    "            designs[lig][rotamer_name] =[]\n",
    "            for i,(j,row) in enumerate(scaffold_df.iterrows()):\n",
    "                if i >= 0:\n",
    "                    cluster = row['cluster']\n",
    "                    indi_cluster_dir = indi_rot_design_dir + '/'.join(cluster.split('/')[0:2]) + \\\n",
    "                                       '_' + cluster.split('/')[2].replace('.list','') + '/'\n",
    "                    predictor_sc_f = glob.glob(f'{indi_cluster_dir}predictor.sc')\n",
    "                    if len(predictor_sc_f) > 0:\n",
    "                        success += 1\n",
    "                        designs[lig][rotamer_name] += predictor_sc_f\n",
    "            print(f'{lig} {rotamer_name} from {success} clusters got designs: {len(designs[lig][rotamer_name])}\\n__________________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n,lig in enumerate(ligands):\n",
    "    if (lig == 'T44'):# or (lig == 'HCY'):\n",
    "        design_dir = f'{scratch_dir}3_prediction_ref2015_oldmethod/{lig}_prediction/'\n",
    "        df_list = []\n",
    "        for rotamer in ligands[lig][2]:\n",
    "            rotamer_name = os.path.basename(rotamer).replace('.pdb','')\n",
    "            for sc in designs[lig][rotamer_name]:\n",
    "                indi_df = pd.read_csv(sc,header=1,delim_whitespace=True)\n",
    "                indi_cluster_dir = '/'.join(sc.split('/')[-3:-1])+'/'\n",
    "                indi_df['indi_cluster_dir'] = indi_cluster_dir\n",
    "                indi_df['cluster'] = scaffold_df.loc[scaffold_df['indi_cluster_dir']==indi_cluster_dir,'cluster'].values[0]\n",
    "                indi_df['rotamer'] = rotamer_name\n",
    "                silent_in = f'{scratch_dir}2_rifdock/{lig}_rifdock/{rotamer_name}/{indi_cluster_dir}out/'+\\\n",
    "                                indi_df.description[0].split('_000000')[0]+'.silent'\n",
    "                if not os.path.isfile(silent_in):\n",
    "                    print(f'Error {silent_in}')\n",
    "                indi_df['silent_in'] = silent_in\n",
    "                df_list.append(indi_df)\n",
    "        all_df = pd.concat(df_list)\n",
    "        all_df['name'] = all_df['description'] + '_' + all_df['rotamer']\n",
    "        all_df.to_csv(f'{design_dir}all_predictor.sc')\n",
    "all_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check burial of tail\n",
    "- Manually add tail and check tail burail\n",
    "- From Gyu Rie \n",
    "- `/home/linnaan/from/gyurie/ligand_linker_orientation_check`\n",
    "1. Generate a params file with an extended linker that would mimic some part of the conjugation linker (doesn't have to be accurate). It will be 'packed' later.\n",
    "@add_linker_params/\n",
    "#You would need a ligand pdb ('hcy.pdb') and a molecule pdb ('linker_newname.pdb' can be used for some cases) to align at least three atoms and add the linker.\n",
    "example:\n",
    "`sh ./cmd`\n",
    "The script will add additional atoms and modify the params file to add proton_chi lines.\n",
    "example output-> hcy_linker_tors.params\n",
    "\n",
    "2. We will use the params file generated from 1. to run a fast packer and calculate atomic depth for the linker atoms. (If the atoms that consist the linker are buried we can filter those out). The modified params file will be used to automatically fill in the missing atoms (linker atoms), so no need to change the input pdb (your design pdb). You just need to use the modified params.\n",
    "script: check_burial.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECK_BURIAL = '/software/conda/envs/pyrosetta/bin/python '+\\ # you should be fine as long as you use pyrosetta\n",
    "               'toolkits/check_burial.py'\n",
    "for n,lig in enumerate(ligands):\n",
    "    if (lig == 'T44'):# or (lig == 'HCY'):\n",
    "        cmds = []\n",
    "        design_dir = f'{scratch_dir}3_prediction_ref2015_oldmethod/{lig}_prediction/'\n",
    "        sel_df = pd.read_csv(f'{scratch_dir}3_prediction/{lig}_prediction/sel_for_2ndpredictor.sc')\n",
    "        os.chdir(design_dir)\n",
    "        for rotamer in ligands[lig][2]:\n",
    "            rotamer_name = os.path.basename(rotamer).replace('.pdb','')\n",
    "            print(f'For {rotamer_name}:________________________________')\n",
    "            rotamer_sel_df = sel_df[sel_df['rotamer']==rotamer_name]\n",
    "            for i,silent_in in enumerate(list(set(rotamer_sel_df.silent_in))):\n",
    "                if i>= 0:\n",
    "                    indi_silent_df = rotamer_sel_df[rotamer_sel_df['silent_in']==silent_in]\n",
    "                    for indi_cluster_dir in list(set(indi_silent_df.indi_cluster_dir)):\n",
    "                        lig_num = 1+int(scaffold_df.loc[scaffold_df['indi_cluster_dir']==indi_cluster_dir,'nres'].values[0])\n",
    "                        indi_cluster_dir = f'{rotamer_name}/'+ indi_cluster_dir\n",
    "                        os.makedirs(indi_cluster_dir,exist_ok=True)\n",
    "                        sel_silent_in = silent_in.replace('.silent','_sel.silent')\n",
    "                        tags = ','.join(list(indi_silent_df['description']))\n",
    "                        cmds.append(f'{CHECK_BURIAL} --silent {sel_silent_in} --lig_atom_names '+\\\n",
    "                              ligands_tails[lig][0] + f' --tags {tags}'+\\\n",
    "                              f' --params_file '+ ligands_tails[lig][1] +\\\n",
    "                              f' --out_sc_file {indi_cluster_dir}'+\\\n",
    "                              os.path.basename(sel_silent_in).replace('.silent','_check_burial.sc'))\n",
    "        cmd_f = f'{design_dir}{lig}_check_burial'\n",
    "        with open(cmd_f,'w') as f:\n",
    "            f.write('\\n'.join(cmds))\n",
    "        if len(cmds) > 0:\n",
    "            make_submit_file(cmds=cmd_f,submitfile=f'{cmd_f}.submit.sh',time=\"3:00:00\",\n",
    "                                group_size=50,logsfolder='logs',cpus=1,mem='1g')\n",
    "            SUBMIT = True\n",
    "            if SUBMIT:\n",
    "                subprocess.check_call(f'sbatch {cmd_f}.submit.sh',shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Collect the burial scores\n",
    "for n,lig in enumerate(ligands):\n",
    "    if (lig == 'T44'):# or (lig == 'HCY'):\n",
    "        df_list = []\n",
    "        design_dir = f'{scratch_dir}3_prediction_ref2015_oldmethod/{lig}_prediction/'\n",
    "        chose_df = pd.read_csv(f'{design_dir}/all_predictor.sc')\n",
    "        sc_fs = glob.glob(design_dir+'*/*/*/*_check_burial.sc')\n",
    "        for sc in sc_fs:\n",
    "            indi_df = pd.read_csv(sc,header=0,delim_whitespace=True)\n",
    "            indi_df['rotamer'] = sc.split('/')[-4]\n",
    "            indi_df['name'] = indi_df['description']+'_'+indi_df['rotamer']\n",
    "            df_list.append(indi_df)\n",
    "        burial_df = pd.concat(df_list)\n",
    "        chose_df = chose_df.merge(burial_df[['name','total_atom_depth']],how='left',on='name')\n",
    "        chose_df['total_atom_depth'] = chose_df['total_atom_depth'].astype(float)\n",
    "        chose_df.to_csv(f'{design_dir}/all_predictor.sc')\n",
    "        sel_chose_df = chose_df[chose_df['total_atom_depth'] <= ligands_tails[lig][2]]\n",
    "        sel_chose_df.to_csv(f'{design_dir}chosen_scaffolds_to_extract.csv')\n",
    "        print(f'{lig} from {len(chose_df)} select {len(sel_chose_df)}, scaffold '+str(len(set(sel_chose_df.cluster))))\n",
    "sel_chose_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3_3. (optional) Randomly select 1000 silent docks for real design to test if predictor reflects real scores\n",
    "- only pick one tag to design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_docks = {}\n",
    "for lig in ligands:\n",
    "    if lig == 'T44':\n",
    "        count = 0\n",
    "        for rotamer in docks[lig]:\n",
    "            if len(docks[lig]) > 0:\n",
    "                count += 1\n",
    "        print(count)\n",
    "        random_docks[lig] = {}\n",
    "        for rotamer in docks[lig]:\n",
    "            if len(docks[lig][rotamer]) > int(1000/count)+1:\n",
    "                random_docks[lig][rotamer] = random.sample(docks[lig][rotamer],int(1000/count))\n",
    "            else:\n",
    "                random_docks[lig][rotamer] = []\n",
    "for lig in random_docks:\n",
    "    if lig == 'T44':\n",
    "        design_dir = f'{scratch_dir}3_prediction_ref2015_oldmethod/{lig}_prediction/'\n",
    "        sum_silent = 0\n",
    "        for rotamer in random_docks[lig]:\n",
    "            sum_silent += len(random_docks[lig][rotamer])\n",
    "    print(f'selected {sum_silent} for {lig}')\n",
    "    ## save random docks in a file for record\n",
    "    json_obj = json.dumps(random_docks,indent=4)\n",
    "    with open(f'{design_dir}sel_random_docks.json','w') as f:\n",
    "        json.dump(random_docks,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test cmd\n",
    "TEST = False\n",
    "PYTHON = '/software/conda/envs/pyrosetta/bin/python'\n",
    "SCRIPTS = '1st_SC_screen/design_ligand_full_noHBNet_1.py'\n",
    "for n,lig in enumerate(ligands):\n",
    "    if lig != 'T44':\n",
    "        design_dir = f'{scratch_dir}3_prediction_real_design/{lig}_prediction/'\n",
    "        os.makedirs(design_dir,exist_ok=True)\n",
    "        cmds = []\n",
    "        os.chdir(design_dir)\n",
    "        sel_dock_json = f'{scratch_dir}3_prediction_ref2015_oldmethod/{lig}_prediction/sel_random_docks.json'\n",
    "        with open(sel_dock_json,'r') as fp:\n",
    "            random_docks = json.load(fp)\n",
    "        for rotamer in ligands[lig][2]:\n",
    "            rotamer_name = os.path.basename(rotamer).replace('.pdb','')\n",
    "            print(f'For {rotamer_name}:________________________________')\n",
    "            for i,dock in enumerate(random_docks[lig][rotamer_name]):\n",
    "                if i >= 0:\n",
    "                    indi_cluster_dir = f'{rotamer_name}/'+ dock.split('/')[-4]+\\\n",
    "                                       '/'+dock.split('/')[-3] + '/'\n",
    "                    cluster_name = '_'.join(('/'.join(dock.split('/')[-4:-2])).split('_')[:-1])+'/'+\\\n",
    "                                 dock.split('/')[-3].split('_')[-1]+'.list'\n",
    "                    os.makedirs(indi_cluster_dir,exist_ok=True)\n",
    "                    pdb = scaffold_df.loc[scaffold_df['cluster']==cluster_name,'path'].values[0]\n",
    "                    lig_num = int(scaffold_df.loc[scaffold_df['cluster']==cluster_name,'nres'].values[0])+1\n",
    "                    # just take the first one\n",
    "                    tag = list(silent_tools.build_silent_index(dock)['index'].keys())[0]\n",
    "                    # you may need to change here, depending on where you put the pssm files\n",
    "                    pssm = home_dir + scaffold_df.loc[scaffold_df['cluster']==cluster_name,'polar_bias_pssm_f'].values[0]\n",
    "                    cmds.append(f'cd {indi_cluster_dir}; {PYTHON} {SCRIPTS} '+\\\n",
    "                                f'--silent {dock} --params ' + ligands[lig][1] + ' ' + \\\n",
    "                                f'--heavy_atms ' + ligands[lig][4] + \\\n",
    "                                f' --tags {tag} --ligand_res_num {lig_num} '+\\\n",
    "                                f'--save_to_pdb True --pssm {pssm}')\n",
    "        cmd_f = f'{design_dir}{lig}_real_cmds'\n",
    "        with open(cmd_f,'w') as fp:\n",
    "            fp.write('\\n'.join(cmds))\n",
    "        print(f'write {len(cmds)} design commands')\n",
    "        make_submit_file(cmds=cmd_f,submitfile=f'{cmd_f}.submit.sh',queue='short',\n",
    "                group_size=1,logsfolder='logs',cpus=1,mem='3g') \n",
    "        SUBMIT = True\n",
    "        if SUBMIT:\n",
    "            subprocess.check_call(f'sbatch {cmd_f}.submit.sh',shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Collect results\n",
    "designs = {}\n",
    "for n,lig in enumerate(ligands):\n",
    "    if n>=0:\n",
    "        designs[lig]={}\n",
    "        design_dir = f'{scratch_dir}3_prediction_real_design/{lig}_prediction/'\n",
    "        for rotamer in ligands[lig][2]:\n",
    "            success = 0\n",
    "            rotamer_name = os.path.basename(rotamer).replace('.pdb','')\n",
    "            indi_rot_design_dir = f'{design_dir}{rotamer_name}/'\n",
    "            designs[lig][rotamer_name] =[]\n",
    "            for i,(j,row) in enumerate(scaffold_df.iterrows()):\n",
    "                if i >= 0:\n",
    "                    cluster = row['cluster']\n",
    "                    indi_cluster_dir = indi_rot_design_dir + '/'.join(cluster.split('/')[0:2]) + \\\n",
    "                                       '_' + cluster.split('/')[2].replace('.list','') + '/'\n",
    "                    if len(glob.glob(f'{indi_cluster_dir}*.sc')) > 0:\n",
    "                        success += 1\n",
    "                        designs[lig][rotamer_name] += (glob.glob(f'{indi_cluster_dir}*.sc'))\n",
    "            print(f'{lig} {rotamer_name} from {success} '+\\\n",
    "                  f'clusters got designs: {len(designs[lig][rotamer_name])}\\n__________________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n,lig in enumerate(ligands):\n",
    "    df_list = []\n",
    "    if n>=0:\n",
    "        design_dir = f'{scratch_dir}3_prediction_real_design/{lig}_prediction/'\n",
    "        for rotamer in ligands[lig][2]:\n",
    "            rotamer_name = os.path.basename(rotamer).replace('.pdb','')\n",
    "            if len(designs[lig][rotamer_name]) > 0:\n",
    "                for sc in designs[lig][rotamer_name]:\n",
    "                    indi_df = pd.read_csv(sc)\n",
    "                    indi_df['rotamer'] = rotamer_name\n",
    "                    indi_df['name'] = indi_df['description'].str.split('.').str[0] + '_' + indi_df['rotamer']\n",
    "                    df_list.append(indi_df)\n",
    "        all_df = pd.concat(df_list)\n",
    "        all_df = all_df.reset_index()\n",
    "        all_df.to_csv(f'{design_dir}all_predictor.sc')\n",
    "all_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3_5. Plot ROC curve to pick cutoff to select docks for real designs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A) Quick predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp\n",
    "import libSlurm\n",
    "imp.reload(libSlurm)\n",
    "from libSlurm import plot_ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate predictor1\n",
    "pred1_FEATURE = 'contact_molecular_surface'\n",
    "for n,lig in enumerate(ligands):\n",
    "    if n>=0:\n",
    "        print(f'predictor1 {lig}________')\n",
    "        df_predictor1 = pd.read_csv(f'{scratch_dir}3_prediction/{lig}_prediction/all_predictor.sc')\n",
    "        df_real = pd.read_csv(f'{scratch_dir}3_prediction_real_design/{lig}_prediction/all_predictor.sc')\n",
    "        print(len(df_predictor1),len(df_real)) #len(df_MPNN),\n",
    "        df_predictor1_has_real = df_predictor1[df_predictor1['name'].isin(list(df_real['name']))]\n",
    "             \n",
    "        df_feature = df_real[['name',pred1_FEATURE]]\n",
    "        df_feature = df_feature.merge(df_predictor1_has_real[['name',pred1_FEATURE]],\n",
    "                     how='left',on='name').rename(columns={'contact_molecular_surface_x':'contact_molecular_surface_real','contact_molecular_surface_y':'contact_molecular_surface_pred1'})\n",
    "        df_feature = df_feature.dropna()\n",
    "        print(len(df_feature))\n",
    "        plot_ROC(df_feature,[pred1_FEATURE],[pred1_FEATURE],real_maker='_real',test_maker='_pred1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate predictor2\n",
    "pred2_FEATURE = ['contact_molecular_surface','ddg2','holes_around_lig','total_hb_to_lig','dsasa']\n",
    "merge_feature = ['contact_molecular_surface','ddg2','holes_around_lig','total_hb_to_lig','dsasa','name']\n",
    "higher = ['contact_molecular_surface','total_hb_to_lig','dsasa']\n",
    "for n,lig in enumerate(ligands):\n",
    "    if n>=0:\n",
    "        print(f'predictor2 {lig}________')\n",
    "        df_predictor2 = pd.read_csv(f'{scratch_dir}3_prediction_ref2015_oldmethod/{lig}_prediction/all_predictor.sc')\n",
    "        df_real = pd.read_csv(f'{scratch_dir}3_prediction_real_design/{lig}_prediction/all_predictor.sc')\n",
    "        df_predictor2['total_hb_to_lig'] = 0\n",
    "        for col in list(df_predictor2.columns):\n",
    "            if 'hb_to' in col:\n",
    "                df_predictor2['total_hb_to_lig'] += df_predictor2[col]\n",
    "        df_real['total_hb_to_lig'] = 0\n",
    "        for col in list(df_real.columns):\n",
    "            if 'hb_to' in col:\n",
    "                df_real['total_hb_to_lig'] += df_real[col]\n",
    "        df_predictor2 = df_predictor2.rename(columns={'ddg_norepack':'ddg2'})\n",
    "        print(len(df_predictor2),len(df_real)) #len(df_MPNN),\n",
    "        df_predictor2_has_real = df_predictor2[df_predictor2['name'].isin(list(df_real['name']))]\n",
    "        \n",
    "        df_feature = df_real[merge_feature]\n",
    "        df_feature = df_feature.merge(df_predictor2_has_real[merge_feature],how='left',on='name')\n",
    "        df_feature = df_feature.dropna()\n",
    "        print(len(df_feature))\n",
    "        for feature in pred2_FEATURE:\n",
    "            df_feature = df_feature.rename(columns={f'{feature}_x':f'{feature}_real',f'{feature}_y':f'{feature}_pred2'})                      \n",
    "        plot_ROC(df_feature,pred2_FEATURE,higher,real_maker='_real',test_maker='_pred2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3_6. Select winner scaffolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Collect results\n",
    "CHECK_DESIGN = True\n",
    "rifdock_dir = f'{scratch_dir}2_rifdock/'\n",
    "quantiles = {\n",
    "            'contact_molecular_surface':[False,[99.9,99,98,97,96,95,90,85,70,50,30,25,15,10,1]],\n",
    "             'dsasa':[False,[99.9,99,98,97,96,95,90,85,70,50,30,25,15,10,1]],\n",
    "             'ddg_norepack':[True,[99.9,99,98,97,96,95,90,85,70,50,30,25,15,10,1]],\n",
    "              'holes_around_lig':[True,[99.9,99,98,97,96,95,90,85,70,50,30,25,15,10,1]],\n",
    "             'total_atom_depth':[True,[99.9,99,98,97,96,95,90,85,70,50,30,25,15,10,1]]\n",
    "            } # select till quantiles are still represented based on ROC\n",
    "for n,lig in enumerate(ligands):\n",
    "    if (lig=='T44'): #or (lig=='HCY'):\n",
    "        design_dir = f'{scratch_dir}3_prediction_ref2015_oldmethod/{lig}_prediction/'\n",
    "        predictor_sc = f'{design_dir}all_predictor.sc'\n",
    "        check_design_dir = f'{design_dir}check_designs_at_quantiles'\n",
    "        os.makedirs(check_design_dir,exist_ok=True)\n",
    "        for feature in quantiles:\n",
    "            predictor_df = pd.read_csv(predictor_sc)\n",
    "            predictor_df['pdb_description'] = predictor_df['description'].str.split('_0000000').str[0]\n",
    "            predictor_df = predictor_df.sort_values(by=feature,ascending=quantiles[feature][0])#.drop_duplicates(subset='cluster',keep='first')\n",
    "            sns.histplot(data=predictor_df,x='rotamer')\n",
    "            for quantile in quantiles[feature][1]:\n",
    "                if quantiles[feature][0]:\n",
    "                    value = predictor_df.quantile(q=(100-quantile)/100,axis=0,interpolation='nearest')[feature]\n",
    "                    print('___________________________________________\\n'+\\\n",
    "                         f'! at quantile {feature} {quantile}: {value}, '+\\\n",
    "                         f'scaffold left: {len(predictor_df[predictor_df[feature]<=value])}')\n",
    "                else:\n",
    "                    value = predictor_df.quantile(q=quantile/100,axis=0,interpolation='nearest')[feature]\n",
    "                    print('___________________________________________\\n'+\\\n",
    "                         f'! at quantile {feature} {quantile}: {value}, '+\\\n",
    "                         f'scaffold left: {len(predictor_df[predictor_df[feature]>=value])}')\n",
    "                pdb_row = predictor_df[predictor_df[feature]==value]\n",
    "                rotamer_name = pdb_row['rotamer'].values[0]\n",
    "                cluster = pdb_row['cluster'].values[0]\n",
    "                silent_f = f'{rifdock_dir}/{lig}_rifdock/{rotamer_name}/'+ cluster.split('/')[-3]+\\\n",
    "                               '/'+cluster.split('/')[-2] + '_' + \\\n",
    "                                cluster.split('/')[-1].replace('.list','') +\\\n",
    "                               '/out/' + pdb_row['description'].values[0].split('_0000000')[0] + '_sel.silent'\n",
    "                tag = pdb_row['description'].values[0]\n",
    "                if os.path.isfile(silent_f):\n",
    "                    os.chdir(check_design_dir)\n",
    "                    #this cmd need silent_tools\n",
    "                    cmd = f'silentextractspecific {silent_f} {tag}; mv {tag[:-2]}*.pdb {feature}{quantile}.pdb'\n",
    "                    subprocess.check_call(cmd,shell=True)\n",
    "                    print(quantile,cmd,end='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### look at the selected designs and check what's the quantile to choose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually edit this\n",
    "# feature:[quantile,ascending=T/F,corresponding_value] #should take top quantile\n",
    "CHOSE_QUANTILE = {\n",
    "                  'T44':{'contact_molecular_surface':[70,False,342],\n",
    "                         'ddg_norepack':[15,True,-8.9],\n",
    "                         'dsasa':[50,False,0.893],\n",
    "                         'holes_around_lig':[15,True,3.47],\n",
    "                         'total_atom_depth':[1,True,8]\n",
    "                         },\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalized_SEL = True\n",
    "for n,lig in enumerate(ligands):\n",
    "    if (lig == 'T44'): #or (lig == 'HCY'):\n",
    "        cmds = []\n",
    "        design_dir = f'{scratch_dir}3_prediction_ref2015_oldmethod/{lig}_prediction/'\n",
    "        predictor_sc = f'{design_dir}chosen_scaffolds_to_extract.csv' #f'{design_dir}all_predictor.sc'\n",
    "        predictor_df = pd.read_csv(predictor_sc)\n",
    "        predictor_df['pdb_description'] = predictor_df['description'].str.split('_0000000').str[0]\n",
    "        chose_df = predictor_df.copy()\n",
    "        print(f'{lig}___________________________________')\n",
    "        print(f'start from {len(chose_df)}')\n",
    "        for feature in CHOSE_QUANTILE[lig]:\n",
    "            chose_df = chose_df.sort_values(by=feature,ascending=CHOSE_QUANTILE[lig][feature][1])\n",
    "            predictor_df = predictor_df.sort_values(by=feature,ascending=CHOSE_QUANTILE[lig][feature][1])\n",
    "            value = CHOSE_QUANTILE[lig][feature][2]\n",
    "            if CHOSE_QUANTILE[lig][feature][1]: #ascending=True\n",
    "                chose_df = chose_df[chose_df[feature] <= value]\n",
    "                print(f'{feature} at quantile {CHOSE_QUANTILE[lig][feature][0]} less than value {value},',\n",
    "                      f'left design {len(chose_df)}')\n",
    "            else:\n",
    "                chose_df = chose_df[chose_df[feature] >= value]\n",
    "                print(f'{feature} at quantile {CHOSE_QUANTILE[lig][feature][0]} greater than value {value},',\n",
    "                      f'left design {len(chose_df)}')\n",
    "        print(f'left designs '+str(len(chose_df)/len(predictor_df)*100)+'%')\n",
    "        print(f'chose scaffolds '+str(len(set(list(chose_df['cluster'])))))\n",
    "        #make_dist_plots(chose_df,CHOSE_QUANTILE[lig].keys())\n",
    "        plot2pandas(chose_df,predictor_df,CHOSE_QUANTILE[lig].keys(),'chose','all',ncols = 4)\n",
    "        \n",
    "        if finalized_SEL:\n",
    "            chose_df['orig_silent_f'] = f'{rifdock_dir}/{lig}_rifdock/'+chose_df['rotamer']+'/'+\\\n",
    "                                        chose_df['indi_cluster_dir']+'out/'+\\\n",
    "                                        chose_df['description'].str.split('_0000000').str[0]+'_sel.silent'\n",
    "            chose_df.to_csv(f'{design_dir}chosen_scaffolds_to_check_burial.csv')\n",
    "            #design these chosen docks for accurate MPNN resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3_7. Extract selected docks by PSSM-based rosetta design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract pdbs. Previously we only dump the scores. To resample using MPNN, we need to use actual designed \n",
    "# pdbs. Thus we need to do quick design of chosen pdbs.\n",
    "chose_designs = {}\n",
    "PYTHON = '/software/conda/envs/pyrosetta/bin/python' # use pyrosetta should work\n",
    "SCRIPTS = '1st_SC_screen/design_ligand_full_noHBNet_1.py'\n",
    "for n,lig in enumerate(ligands):\n",
    "    if (lig == 'T44'):# or (lig == 'HCY'):\n",
    "        cmds = []\n",
    "        design_dir = f'{scratch_dir}3_prediction_ref2015_oldmethod/{lig}_prediction/'\n",
    "        sel_chose_df = pd.read_csv(f'{design_dir}chosen_scaffolds_to_check_burial.csv')\n",
    "        #design these chosen docks for accurate MPNN resampling\n",
    "        chosen_design_dir = f'{design_dir}chosen_designs_to_resample/'\n",
    "        for i,(j,row) in enumerate(sel_chose_df.iterrows()):\n",
    "            if i >= 0:\n",
    "                rotamer_name = row['rotamer']\n",
    "                cluster = row['cluster']\n",
    "                silent_f = row['silent_in']\n",
    "                indi_cluster_dir = scaffold_df.loc[scaffold_df['cluster']==cluster,\n",
    "                                                   'indi_cluster_dir'].values[0]\n",
    "                # you may need to change here, depending on where you put your pssm\n",
    "                pssm = home_dir + scaffold_df.loc[scaffold_df['cluster']==cluster,\n",
    "                                                   'polar_bias_pssm_f'].values[0]\n",
    "                lig_num = 1+int(scaffold_df.loc[scaffold_df['cluster']==cluster,'nres'].values[0])\n",
    "                tag = row['description']\n",
    "                os.makedirs(f'{chosen_design_dir}{rotamer_name}/{indi_cluster_dir}',exist_ok=True)\n",
    "                end_pdb = f'{chosen_design_dir}{rotamer_name}/{indi_cluster_dir}{tag}_{rotamer_name}.pdb'\n",
    "                if (os.path.isfile(silent_f) == True) and (os.path.isfile(end_pdb) == False):\n",
    "                    cmds.append(f'cd {chosen_design_dir}{rotamer_name}/{indi_cluster_dir}; '+\\\n",
    "                                            f'{PYTHON} {SCRIPTS} '+\\\n",
    "                                            f'--silent {silent_f} --params ' + ligands[lig][1] + ' ' + \\\n",
    "                                            f'--heavy_atms ' + ligands[lig][4] + \\\n",
    "                                            f' --pssm {pssm} ' + \\\n",
    "                                            f' --tags {tag} --ligand_res_num {lig_num} '+\\\n",
    "                                            f'--save_to_pdb True --suffix _{rotamer_name}')\n",
    "\n",
    "                else:\n",
    "                    continue\n",
    "                    #print(f'{silent_f} not there or already designed!')\n",
    "        cmd_f = f'{design_dir}{lig}_extract_chosen_comp'\n",
    "        with open(cmd_f,'w') as f:\n",
    "            f.write('\\n'.join(cmds))\n",
    "        make_submit_file(cmds=cmd_f,submitfile=f'{cmd_f}.submit.sh',time='1:00:00',group_size=3,\n",
    "                            logsfolder='logs',cpus=1,mem='2g')\n",
    "        SUBMIT = True\n",
    "        if SUBMIT:\n",
    "            subprocess.check_call(f'sbatch {cmd_f}.submit.sh',shell=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collect design results\n",
    "for n,lig in enumerate(ligands):\n",
    "    if lig == 'T44':\n",
    "        df_list = []\n",
    "        design_dir = f'{scratch_dir}3_prediction_ref2015_oldmethod/{lig}_prediction/'\n",
    "        sel_chose_df = pd.read_csv(f'{design_dir}chosen_scaffolds_to_extract.csv')\n",
    "        sc_fs = glob.glob(f'{design_dir}chosen_designs_to_resample/*/*/*/*.sc')\n",
    "        for sc in sc_fs:\n",
    "            indi_df = pd.read_csv(sc)\n",
    "            indi_df['pdb_path'] = sc.replace('.sc','.pdb')\n",
    "            indi_df['indi_cluster_dir'] = '/'.join(sc.split('/')[-3:-1])+'/'\n",
    "            indi_df['cluster'] = scaffold_df.loc[scaffold_df['indi_cluster_dir']=='/'.join(sc.split('/')[-3:-1])+'/','cluster'].values[0]\n",
    "            df_list.append(indi_df)\n",
    "        all_df = pd.concat(df_list)\n",
    "        sel_chose_df['name'] = sel_chose_df['name']+'.pdb'\n",
    "        all_df = all_df.merge(sel_chose_df[['name','total_atom_depth']],how='left',\n",
    "                              left_on='description',right_on='name')\n",
    "        all_df['group'] = 'original'\n",
    "        all_df['rotamer'] = all_df['pdb_path'].str.split('/').str[-4]\n",
    "\n",
    "        common_features = ['SC', 'ala_core_count', 'buns_all_heavy_ball',\n",
    "       'buns_bb_heavy_ball', 'buns_sc_heavy_ball', 'cavity',\n",
    "       'contact_molecular_surface', 'ddg2', 'dsasa', 'geometry', 'hb_lr_bb',\n",
    "       'hb_lr_bb_per_res', 'hb_sr_bb', 'hb_sr_bb_per_res', 'hole',\n",
    "       'holes_around_lig', 'hydrophobic_residue_contacts',\n",
    "       'interface_buried_sasa', 'interface_sc', 'mismatch_probability', 'nALA',\n",
    "       'nARG', 'nHIS', 'nMET', 'sap_A', 'sap_all', 'sbuns_all_heavy',\n",
    "       'sbuns_all_heavy_no_ligand', 'score', 'score_per_res', 'sspred_overall',\n",
    "       'timed', 'vbuns_all_heavy', 'vbuns_all_heavy_no_ligand', 'fa_atr', 'fa_rep', \n",
    "       'fa_sol', 'fa_intra_atr_xover4','fa_intra_rep_xover4', 'fa_intra_sol_xover4', \n",
    "       'lk_ball', 'lk_ball_iso','lk_ball_bridge', 'lk_ball_bridge_uncpl', 'fa_elec', 'fa_intra_elec',\n",
    "       'pro_close', 'hbond_sr_bb', 'hbond_lr_bb', 'hbond_bb_sc', 'hbond_sc',\n",
    "       'dslf_fa13', 'omega', 'fa_dun_dev', 'fa_dun_rot', 'fa_dun_semi',\n",
    "       'p_aa_pp', 'hxl_tors', 'rama_prepro', 'gen_bonded', 'total','total_atom_depth', 'total_hb_to_lig']\n",
    "        related_features = common_features\n",
    "        all_df['total_hb_to_lig'] = 0\n",
    "        for feature in list(all_df.columns):\n",
    "            if 'hb_to' in feature:\n",
    "                all_df['total_hb_to_lig'] += all_df[feature]\n",
    "        all_df.to_csv(f'{design_dir}score_chosen_scaffolds_to_extract.csv') \n",
    "        make_dist_plots(all_df,related_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3_8. (optional) if okay number of designs got  at this step, can also select final design cretiera\n",
    "- in general is good to check your designs to see if there is anything wrong. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check final designs by looking at designs at different percentile\n",
    "quantiles = {\n",
    "             'contact_molecular_surface':[False,[99.9,99,98,97,96,95,90,85,70,50,30,25,15,10,1]],\n",
    "              'dsasa':[False,[99.9,99,98,97,96,95,90,85,70,50,30,25,15,10,1]],\n",
    "              'ddg2':[True,[99.9,99,98,97,96,95,90,85,70,50,30,25,15,10,1]],\n",
    "              'holes_around_lig':[True,[99.9,99,98,97,96,95,90,85,70,50,30,25,15,10,1]],\n",
    "             'total_atom_depth':[True,[99.9,99,98,97,96,95,90,85,70,50,30,25,15,10,1]]\n",
    "            } # select till quantiles are still represented based on ROC\n",
    "for n,lig in enumerate(ligands):\n",
    "    if lig == 'T44':\n",
    "        design_dir= f'{scratch_dir}3_prediction_ref2015_oldmethod/{lig}_prediction/'\n",
    "        os.chdir(design_dir)\n",
    "        all_sc = f'{design_dir}score_chosen_scaffolds_to_extract.csv'\n",
    "        all_df = pd.read_csv(all_sc)\n",
    "        print(len(all_df))\n",
    "        check_design_dir = f'{design_dir}check_designs_at_qantiles/'\n",
    "        os.makedirs(check_design_dir,exist_ok=True)\n",
    "        for feature in quantiles:\n",
    "            all_df = all_df.sort_values(by=feature,ascending=quantiles[feature][0])\n",
    "            for quantile in quantiles[feature][1]:\n",
    "                if quantiles[feature][0]:\n",
    "                    value = all_df.quantile(q=(100-quantile)/100,axis=0,interpolation='nearest')[feature]\n",
    "                    print('___________________________________________')\n",
    "                    print(f'! at quantile {feature} {quantile}: {value}, scaffold left: {len(all_df[all_df[feature]<=value])}')\n",
    "                else:\n",
    "                    value = all_df.quantile(q=quantile/100,axis=0,interpolation='nearest')[feature]\n",
    "                    print('___________________________________________')\n",
    "                    print(f'! at quantile {feature} {quantile}: {value}, scaffold left: {len(all_df[all_df[feature]>=value])}')\n",
    "                pdb_row = all_df[all_df[feature]==value].head(1)\n",
    "                pdb = pdb_row.pdb_path.values[0]\n",
    "                if os.path.isfile(pdb):\n",
    "                    os.chdir(check_design_dir)\n",
    "                    cmd = f'cp {pdb} {feature}{quantile}.pdb'\n",
    "                    subprocess.check_call(cmd,shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### look at the selected designs and check what's the quantile to choose. Only keep the best ones, good enough for order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually edit this\n",
    "# feature:[quantile,ascending=T/F,actual_value] #should take top quantile\n",
    "# These are Rosetta filters used for final selection\n",
    "FINAL_CHOSE_QUANTILE = {\n",
    "                  'T44':{'total_hb_to_lig':[5,False,5],\n",
    "                         'contact_molecular_surface':[50,False,367],\n",
    "                         'ddg2':[50,True,-26.6], #this one visually cannot distinguish\n",
    "                         'dsasa':[70,False,0.976],\n",
    "                         'holes_around_lig':[30,True,1.58],\n",
    "                         'total_atom_depth':[50,True,6.16] #don't use this feature for CHD since checked before\n",
    "                        }\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalized_SEL = True\n",
    "for n, lig in enumerate(ligands):\n",
    "    if lig == 'T44':\n",
    "        design_dir = f'{scratch_dir}3_prediction_ref2015_oldmethod/{lig}_prediction/'\n",
    "        all_df = pd.read_csv(f'{design_dir}score_chosen_scaffolds_to_extract.csv')\n",
    "        chose_df = all_df.copy()\n",
    "        print(f'{lig} start from {len(chose_df)}')\n",
    "        for feature in FINAL_CHOSE_QUANTILE[lig]:\n",
    "            chose_df = chose_df.sort_values(by=feature,ascending=FINAL_CHOSE_QUANTILE[lig][feature][1])\n",
    "            value = FINAL_CHOSE_QUANTILE[lig][feature][2]\n",
    "            if FINAL_CHOSE_QUANTILE[lig][feature][1]: #ascending=True\n",
    "                chose_df = chose_df[chose_df[feature] <= value]\n",
    "                print(f'{feature} at quantile {FINAL_CHOSE_QUANTILE[lig][feature][0]} less than value {value},',\n",
    "                      f'left scaffolds {len(chose_df)}')\n",
    "            else:\n",
    "                chose_df = chose_df[chose_df[feature] >= value]\n",
    "                print(f'{feature} at quantile {FINAL_CHOSE_QUANTILE[lig][feature][0]} greater than value {value},',\n",
    "                      f'left scaffolds {len(chose_df)}')\n",
    "        print(f'chose designs '+str(len(chose_df)/len(all_df)*100)+'%')\n",
    "        print(f'chose scaffolds '+str(len(set(list(chose_df['cluster'])))))\n",
    "        plot2pandas(chose_df,all_df,FINAL_CHOSE_QUANTILE[lig].keys(),'chose','all',ncols = 4)\n",
    "        \n",
    "        if finalized_SEL:\n",
    "            # this is the file to include for final design selection as well\n",
    "            chose_df.to_csv(f'{design_dir}final_chosen_scaffolds_to_resample_scaffolds.csv')\n",
    "            #design these chosen docks for accurate MPNN resampling\n",
    "            selected_dir = f'{design_dir}sel_for_af2/'\n",
    "            os.makedirs(selected_dir,exist_ok=True)\n",
    "            with_lig_dir = f'{selected_dir}with_lig/'\n",
    "            os.makedirs(with_lig_dir,exist_ok=True)\n",
    "            AF2_dir = f'{selected_dir}AF2_results/'\n",
    "            os.makedirs(AF2_dir,exist_ok=True)\n",
    "            chA_only = f'{selected_dir}chA_only/'\n",
    "            os.makedirs(chA_only,exist_ok=True)\n",
    "            for i,(j,row) in enumerate(chose_df.iterrows()):\n",
    "                pdb_path = row['pdb_path']\n",
    "                cmd = f'cp -n {pdb_path} {with_lig_dir}'\n",
    "                subprocess.check_call(cmd,shell=True)\n",
    "                cmd = f'grep \" A \" {pdb_path} > {chA_only}'+os.path.basename(pdb_path)\n",
    "                subprocess.check_call(cmd,shell=True)\n",
    "            \n",
    "        #plot results\n",
    "        plot2pandas(chose_df,all_df,FINAL_CHOSE_QUANTILE[lig].keys(),'chosen','all',ncols=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check AF2 score for these designs\n",
    "# ref: https://github.com/google-deepmind/alphafold.git\n",
    "AF2 = '/software/conda/envs/mlfold/bin/python SM_af2/run_af2.py' # follow af2 instruction on docker/environment setting for this script\n",
    "BATCH = 15 # request 32g, 200 aa need 2 g, can load 32/2 = 16 proteins at maximum\n",
    "for n,lig in enumerate(ligands):\n",
    "    if lig == 'T44':\n",
    "        cmds = []\n",
    "        design_dir = f'{scratch_dir}3_prediction_ref2015_oldmethod/{lig}_prediction/'\n",
    "        os.chdir(design_dir)\n",
    "        chose_df = pd.read_csv(f'{design_dir}final_chosen_scaffolds_to_resample_scaffolds.csv')\n",
    "        selected_dir = f'{design_dir}sel_for_af2/'\n",
    "        with_lig_dir = f'{selected_dir}with_lig/'\n",
    "        AF2_dir = f'{selected_dir}AF2_results/'\n",
    "        chA_only = f'{selected_dir}chA_only/'\n",
    "        for rotamer in list(set(chose_df.rotamer)):\n",
    "            print(f'For {rotamer}:________________________________')\n",
    "            rotamer_sel_df = chose_df[chose_df['rotamer']==rotamer]\n",
    "            for cluster in list(set(rotamer_sel_df.cluster)):\n",
    "                cluster_chose_df = rotamer_sel_df[rotamer_sel_df['cluster']==cluster]\n",
    "                indi_cluster_dir = scaffold_df.loc[scaffold_df['cluster']==cluster,\n",
    "                                                   'indi_cluster_dir'].values[0]\n",
    "                if len(cluster_chose_df) > 0:\n",
    "                    length = int(scaffold_df.loc[scaffold_df['cluster']==cluster,'nres'].values[0])\n",
    "                    pdbs = list(cluster_chose_df['pdb_path'])\n",
    "                    af2_indi_dir = f'{chA_only}{rotamer}/{indi_cluster_dir}'\n",
    "                    af2_result_dir = f'{AF2_dir}{rotamer}/{indi_cluster_dir}'\n",
    "                    os.makedirs(af2_indi_dir,exist_ok=True)\n",
    "                    os.makedirs(af2_result_dir,exist_ok=True)\n",
    "                    fastas = []\n",
    "                    for i,pdb in enumerate(pdbs): \n",
    "                        fasta_f = f'{af2_indi_dir}'+os.path.basename(pdb)[:-4]+'.fasta'\n",
    "                        af2_model = glob.glob(af2_result_dir+'/'+os.path.basename(pdb)[:-4]+\\\n",
    "                                              '*_model_*.pdb')\n",
    "                        if len(af2_model) > 0:\n",
    "                            subprocess.check_call(f'rm -f {fasta_f}',shell=True)\n",
    "                        else:\n",
    "                            record_gen = SeqIO.parse(pdb,\"pdb-atom\")\n",
    "                            for record in record_gen:\n",
    "                                seq = str(record.seq)\n",
    "                            with open(fasta_f,'w') as f:\n",
    "                                f.write('>'+os.path.basename(pdb)[:-4]+'\\n'+seq)\n",
    "                            fastas.append(fasta_f)\n",
    "                    if len(fastas) > 0:\n",
    "                        fasta_list = [fastas[i:i + BATCH] for i in range(0, len(fastas), BATCH)]\n",
    "                        for fasta_fs in fasta_list:\n",
    "                            batch_size = len(fasta_fs)\n",
    "                            fasta_fs = ','.join(fasta_fs)\n",
    "                            cmds.append(f'{AF2} --fasta_fs {fasta_fs} --out_dir {af2_result_dir} '+\\\n",
    "                                        f' --min_length {length} --max_length {length+5} --num_models 5 '+\\\n",
    "                                        f' --batch_size {batch_size} ')\n",
    "        if len(cmds) > 0:\n",
    "            cmd_f = f'{lig}_check_af2_cmd'\n",
    "            with open(cmd_f,'w') as f:\n",
    "                f.write('\\n'.join(cmds))\n",
    "            make_submit_file(cmds=cmd_f,submitfile=f'{cmd_f}.submit.sh',time=\"2-0:00:00\",\n",
    "            group_size=int(len(cmds)/4),logsfolder='logs',cpus=2,mem='32g',needs_gpu=True)\n",
    "            SUBMIT = False\n",
    "            if SUBMIT:\n",
    "                subprocess.check_call(f'sbatch {cmd_f}.submit.sh',shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add AF2 plDDT scores and RMSD\n",
    "for n,lig in enumerate(ligands):\n",
    "    if lig == 'T44':\n",
    "        cmds = []\n",
    "        df_list = []\n",
    "        design_dir = f'{scratch_dir}3_prediction_ref2015_oldmethod/{lig}_prediction/'\n",
    "        os.chdir(design_dir)\n",
    "        chose_df = pd.read_csv(f'{design_dir}final_chosen_scaffolds_to_resample_scaffolds.csv')\n",
    "        chose_df['rotamer'] = chose_df['pdb_path'].str.split('/').str[-4]\n",
    "        for col in list(chose_df.columns):\n",
    "            if 'model' in col:\n",
    "                chose_df = chose_df.drop([col],axis=1)\n",
    "        selected_dir = f'{design_dir}sel_for_af2/'\n",
    "        with_lig_dir = f'{selected_dir}with_lig/'\n",
    "        chA_dir = f'{selected_dir}chA_only/'\n",
    "        AF2_dir = f'{selected_dir}AF2_results/'\n",
    "        for rotamer in list(set(chose_df.rotamer)):\n",
    "            print(f'For {rotamer}:________________________________')\n",
    "            rotamer_sel_df = chose_df[chose_df['rotamer']==rotamer]\n",
    "            for cluster in list(set(rotamer_sel_df.cluster)):\n",
    "                cluster_chose_df = rotamer_sel_df[rotamer_sel_df['cluster']==cluster]\n",
    "                indi_cluster_dir = scaffold_df.loc[scaffold_df['cluster']==cluster,\n",
    "                                                   'indi_cluster_dir'].values[0]\n",
    "                if len(cluster_chose_df) > 0:\n",
    "                    length = int(scaffold_df.loc[scaffold_df['cluster']==cluster,'nres'].values[0])\n",
    "                    pdbs = list(cluster_chose_df['pdb_path'])\n",
    "                    af2_indi_dir = f'{chA_dir}{rotamer}/{indi_cluster_dir}'\n",
    "                    af2_result_dir = f'{AF2_dir}{rotamer}/{indi_cluster_dir}'\n",
    "                    for i,pdb in enumerate(pdbs): \n",
    "                        pdb_info = {}\n",
    "                        af2_models = glob.glob(af2_result_dir+\\\n",
    "                                               os.path.basename(pdb)[:-4]+'*_model_*.pdb')\n",
    "                        if len(af2_models) > 0:\n",
    "                            chA = f'{af2_indi_dir}'+os.path.basename(pdb)\n",
    "                            if not os.path.isfile(chA):\n",
    "                                subprocess.check_call(f'grep \" A \" {pdb} > {chA}',shell=True)\n",
    "                            for af2_model in af2_models:\n",
    "                                with open(af2_model,'r') as f:\n",
    "                                    for line in f:\n",
    "                                        if 'plddt' in line:\n",
    "                                            pdb_info[line.split()[0]] = [line.split()[-1]]\n",
    "                                if 'model_4' in af2_model:\n",
    "                                    pdb_info['unrelaxed_model_4'] = [af2_model]\n",
    "                                    rmsd = get_RMSD(TMalign(chA,af2_model))\n",
    "                                    pdb_info['rmsd_model4'] = rmsd\n",
    "                            pdb_info['pdb_path'] = [pdb]\n",
    "                            indi_df = pd.DataFrame.from_dict(pdb_info)\n",
    "                            df_list.append(indi_df)\n",
    "                        else:\n",
    "                            continue\n",
    "                    \n",
    "        all_plddt_df = pd.concat(df_list)\n",
    "        chose_df = chose_df.merge(all_plddt_df,how='left',on='pdb_path')\n",
    "        chose_df.to_csv(f'{design_dir}final_chosen_scaffolds_to_resample_scaffolds.csv')\n",
    "## Final filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Copy good designs to another folder, these are for order\n",
    "RMSD = 1.5 # 1-1.5 A is probably good\n",
    "plDDT  = 85 # > 85 is good, only plddt is high enough, we can be more confident on sc.\n",
    "cutoff_final = True\n",
    "for n,lig in enumerate(ligands):\n",
    "    if lig == 'T44':\n",
    "        cmds = []\n",
    "        df_list = []\n",
    "        design_dir = f'{scratch_dir}3_prediction_ref2015_oldmethod/{lig}_prediction/'\n",
    "        os.chdir(design_dir)\n",
    "        chose_df = pd.read_csv(f'{design_dir}final_chosen_scaffolds_to_resample_scaffolds.csv')\n",
    "        order_dir = f'{scratch_dir}9_for_order/{lig}_design/'\n",
    "        enriched_design_dir = f'{order_dir}1st_round_enriched_from_good_clusters/'\n",
    "        os.makedirs(enriched_design_dir,exist_ok=True)\n",
    "        check = chose_df[~chose_df['unrelaxed_model_4'].isna()]\n",
    "        sel_for_order = check[((check['model_1'] >= plDDT) | (check['model_2'] >=  plDDT) |\\\n",
    "                               (check['model_3'] >= plDDT) | (check['model_4'] >=  plDDT) |\\\n",
    "                               (check['model_5'] >=  plDDT)) & (check['rmsd_model4'] <= RMSD)]\n",
    "        #plot results\n",
    "        print(f'{len(sel_for_order)} designs also passed AF2, rate {len(sel_for_order)}/{len(chose_df)}={100*len(sel_for_order)/len(chose_df)}%')\n",
    "        features = ['contact_molecular_surface','dsasa','holes_around_lig',\\\n",
    "                    'ddg2','total_hb_to_lig','total_atom_depth','model_4','rmsd_model4']\n",
    "        plot2pandas(sel_for_order,chose_df,features,'pass_rosetta_af2','pass_rosetta',ncols=4)\n",
    "        \n",
    "        if cutoff_final:\n",
    "            sel_for_order.to_csv(f'{order_dir}1st_orders_from_scaffold_enrichment.csv')\n",
    "            for i,(j,row) in enumerate(sel_for_order.iterrows()):\n",
    "                pdb = row['pdb_path']\n",
    "                cmd = f'cp -n {pdb} {enriched_design_dir}'\n",
    "                subprocess.check_call(cmd,shell=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "common_use",
   "language": "python",
   "name": "common_use"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
